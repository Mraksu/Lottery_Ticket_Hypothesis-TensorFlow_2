{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lottery Ticket Hypothesis: _Conv-2_ CNN for CIFAR10\n",
    "\n",
    "Implementation of the hypothesis using 2 convolutional layers having filer size of 3 x 3 followed by a max pooling layer, followed by two dense layers having 256 neurons in each of them, follwed by 10 output neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/arjun/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import AveragePooling2D, Conv2D, MaxPooling2D, ReLU\n",
    "from tensorflow.keras import models, layers, datasets\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "# import math\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60\n",
    "num_classes = 10\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and cleaning:\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "\n",
    "# Load CIFAR-10 dataset-\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'input_shape' which will be used = (32, 32, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 3, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "print(\"\\n'input_shape' which will be used = {0}\\n\".format(input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to floating point types-\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalize the training and testing datasets-\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors/target to binary class matrices or one-hot encoded values-\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of training and testing sets are:\n",
      "X_train.shape = (50000, 32, 32, 3), y_train.shape = (50000, 10)\n",
      "X_test.shape = (10000, 32, 32, 3), y_test.shape = (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDimensions of training and testing sets are:\")\n",
    "print(\"X_train.shape = {0}, y_train.shape = {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test.shape = {0}, y_test.shape = {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST dataset for _GradientTape_ training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets-\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(buffer_size = 20000, reshuffle_each_iteration = True).batch(batch_size = batch_size, drop_remainder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.batch(batch_size=batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimizer and loss function for training-\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select metrics to measure the error & accuracy of model.\n",
    "# These metrics accumulate the values over epochs and then\n",
    "# print the overall result-\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'end_step parameter' for this dataset =  83400\n"
     ]
    }
   ],
   "source": [
    "# The model is first trained without any pruning for 'num_epochs' epochs-\n",
    "epochs = num_epochs\n",
    "\n",
    "num_train_samples = X_train.shape[0]\n",
    "\n",
    "end_step = np.ceil(1.0 * num_train_samples / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "print(\"'end_step parameter' for this dataset =  {0}\".format(end_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters to be used for layer-wise pruning, NO PRUNING is done here:\n",
    "pruning_params_unpruned = {\n",
    "    'pruning_schedule': sparsity.ConstantSparsity(\n",
    "        target_sparsity=0.0, begin_step=0,\n",
    "        end_step = end_step, frequency=100\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruned_nn(pruning_params_conv, pruning_params_fc):\n",
    "    \"\"\"\n",
    "    Function to define the architecture of a neural network model\n",
    "    following Conv-2 architecture for CIFAR-10 dataset and using\n",
    "    provided parameter which are used to prune the model.\n",
    "    \n",
    "    Conv-2 architecture-\n",
    "    64, 64, pool  -- convolutions\n",
    "    256, 256, 10  -- fully connected layers\n",
    "    \n",
    "    Input: 'pruning_params' Python 3 dictionary containing parameters which are used for pruning\n",
    "    Output: Returns designed and compiled neural network model\n",
    "    \"\"\"\n",
    "    \n",
    "    pruned_model = Sequential()\n",
    "    \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        Conv2D(\n",
    "            filters = 64, kernel_size = (3, 3),\n",
    "            activation='relu', kernel_initializer = tf.initializers.GlorotUniform(),\n",
    "            strides = (1, 1), padding = 'same',\n",
    "            input_shape=(32, 32, 3)\n",
    "        ),\n",
    "        **pruning_params_conv)\n",
    "    )\n",
    "        \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        Conv2D(\n",
    "            filters = 64, kernel_size = (3, 3),\n",
    "            activation='relu', kernel_initializer = tf.initializers.GlorotUniform(),\n",
    "            strides = (1, 1), padding = 'same'\n",
    "        ),\n",
    "        **pruning_params_conv)\n",
    "    )\n",
    "    \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        MaxPooling2D(\n",
    "            pool_size = (2, 2),\n",
    "            strides = (2, 2)\n",
    "        ),\n",
    "        **pruning_params_conv)\n",
    "    )\n",
    "    \n",
    "    pruned_model.add(Flatten())\n",
    "    \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        Dense(\n",
    "            units = 256, activation='relu',\n",
    "            kernel_initializer = tf.initializers.GlorotUniform()\n",
    "        ),\n",
    "        **pruning_params_fc)\n",
    "    )\n",
    "    \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        Dense(\n",
    "            units = 256, activation='relu',\n",
    "            kernel_initializer = tf.initializers.GlorotUniform()\n",
    "        ),\n",
    "        **pruning_params_fc)\n",
    "    )\n",
    "    \n",
    "    pruned_model.add(sparsity.prune_low_magnitude(\n",
    "        Dense(\n",
    "            units = 10, activation='softmax'\n",
    "        ),\n",
    "        **pruning_params_fc)\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Compile pruned CNN-\n",
    "    pruned_model.compile(\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        # optimizer='adam',\n",
    "        optimizer=tf.keras.optimizers.Adam(lr = 0.0002),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return pruned_model\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pruning step callback to peg the pruning step to the optimizer's\n",
    "# step. Also add a callback to add pruning summaries to tensorboard\n",
    "callback = [\n",
    "             sparsity.UpdatePruningStep(),\n",
    "             # sparsity.PruningSummaries(log_dir = logdir, profile_batch=0),\n",
    "             tf.keras.callbacks.EarlyStopping(\n",
    "                 monitor='val_loss', patience = 3,\n",
    "                 min_delta=0.001\n",
    "             )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:183: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "# Initialize a CNN model-\n",
    "orig_model = pruned_nn(pruning_params_unpruned, pruning_params_unpruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip model of it's pruning parameters\n",
    "orig_model_stripped = sparsity.strip_pruning(orig_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random weights-\n",
    "orig_model.save_weights(\"Conv_2_CIFAR_Ramdom_Weights.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save random weights-\n",
    "orig_model.save_weights(\"Conv_2_CIFAR_Winning_Ticket.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_conv2d ( (None, 32, 32, 64)        3522      \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 32, 32, 64)        73794     \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 16, 16, 64)        1         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense (P (None, 256)               8388866   \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 256)               131330    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_2  (None, 10)                5132      \n",
      "=================================================================\n",
      "Total params: 8,602,645\n",
      "Trainable params: 4,301,642\n",
      "Non-trainable params: 4,301,003\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get CNN summary-\n",
    "orig_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer-wise pruning:\n",
    "The Lottery Ticket Hypothesis follows a _layer-wise pruning_ heuristic, where the fully-connected (fc) layers are pruned at the rate of 20% per iterative\n",
    "pruning round and the convolutional (conv) layers are pruned at the rate of 10% per iterative pruning round.\n",
    "\n",
    "Therefore, there is a need to compute the percentage of weights being pruned for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of trainable parameters = 4301642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of convolutional parameters-\n",
    "conv1 = 1792\n",
    "conv2 = 36928\n",
    "\n",
    "# number of fully-connected dense parameters-\n",
    "dense1 = 4194560\n",
    "dense2 = 65792\n",
    "op_layer = 2570\n",
    "\n",
    "\n",
    "# total number of parameters-\n",
    "total_params = conv1 + conv2 + dense1 + dense2 + op_layer\n",
    "\n",
    "print(\"\\nTotal number of trainable parameters = {0}\\n\".format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum pruning performed is till 0.5% of all parameters-\n",
    "max_pruned_params = 0.005 * total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_tot_params = total_params\n",
    "loc_conv1 = conv1\n",
    "loc_conv2 = conv2\n",
    "loc_dense1 = dense1\n",
    "loc_dense2 = dense2\n",
    "loc_op_layer = op_layer\n",
    "\n",
    "# variable to count number of pruning rounds-\n",
    "n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to hold percentage of weights pruned in each round for all layers in CNN-\n",
    "conv1_pruning = []\n",
    "conv2_pruning = []\n",
    "dense1_pruning = []\n",
    "dense2_pruning = []\n",
    "op_layer_pruning = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conv1 = 1612.800, Conv2 = 33235.200\n",
      "Dense1 = 3355648.000, Dense2 = 52633.600 & O/p layer = 2056.000\n",
      "Total number of parameters = 3445185.600\n",
      "\n",
      "\n",
      "Conv1 = 1451.520, Conv2 = 29911.680\n",
      "Dense1 = 2684518.400, Dense2 = 42106.880 & O/p layer = 1644.800\n",
      "Total number of parameters = 2759633.280\n",
      "\n",
      "\n",
      "Conv1 = 1306.368, Conv2 = 26920.512\n",
      "Dense1 = 2147614.720, Dense2 = 33685.504 & O/p layer = 1315.840\n",
      "Total number of parameters = 2210842.944\n",
      "\n",
      "\n",
      "Conv1 = 1175.731, Conv2 = 24228.461\n",
      "Dense1 = 1718091.776, Dense2 = 26948.403 & O/p layer = 1052.672\n",
      "Total number of parameters = 1771497.043\n",
      "\n",
      "\n",
      "Conv1 = 1058.158, Conv2 = 21805.615\n",
      "Dense1 = 1374473.421, Dense2 = 21558.723 & O/p layer = 842.138\n",
      "Total number of parameters = 1419738.054\n",
      "\n",
      "\n",
      "Conv1 = 952.342, Conv2 = 19625.053\n",
      "Dense1 = 1099578.737, Dense2 = 17246.978 & O/p layer = 673.710\n",
      "Total number of parameters = 1138076.820\n",
      "\n",
      "\n",
      "Conv1 = 857.108, Conv2 = 17662.548\n",
      "Dense1 = 879662.989, Dense2 = 13797.582 & O/p layer = 538.968\n",
      "Total number of parameters = 912519.196\n",
      "\n",
      "\n",
      "Conv1 = 771.397, Conv2 = 15896.293\n",
      "Dense1 = 703730.391, Dense2 = 11038.066 & O/p layer = 431.174\n",
      "Total number of parameters = 731867.322\n",
      "\n",
      "\n",
      "Conv1 = 694.258, Conv2 = 14306.664\n",
      "Dense1 = 562984.313, Dense2 = 8830.453 & O/p layer = 344.940\n",
      "Total number of parameters = 587160.627\n",
      "\n",
      "\n",
      "Conv1 = 624.832, Conv2 = 12875.997\n",
      "Dense1 = 450387.451, Dense2 = 7064.362 & O/p layer = 275.952\n",
      "Total number of parameters = 471228.594\n",
      "\n",
      "\n",
      "Conv1 = 562.349, Conv2 = 11588.398\n",
      "Dense1 = 360309.960, Dense2 = 5651.490 & O/p layer = 220.761\n",
      "Total number of parameters = 378332.958\n",
      "\n",
      "\n",
      "Conv1 = 506.114, Conv2 = 10429.558\n",
      "Dense1 = 288247.968, Dense2 = 4521.192 & O/p layer = 176.609\n",
      "Total number of parameters = 303881.441\n",
      "\n",
      "\n",
      "Conv1 = 455.502, Conv2 = 9386.602\n",
      "Dense1 = 230598.375, Dense2 = 3616.953 & O/p layer = 141.287\n",
      "Total number of parameters = 244198.720\n",
      "\n",
      "\n",
      "Conv1 = 409.952, Conv2 = 8447.942\n",
      "Dense1 = 184478.700, Dense2 = 2893.563 & O/p layer = 113.030\n",
      "Total number of parameters = 196343.186\n",
      "\n",
      "\n",
      "Conv1 = 368.957, Conv2 = 7603.148\n",
      "Dense1 = 147582.960, Dense2 = 2314.850 & O/p layer = 90.424\n",
      "Total number of parameters = 157960.338\n",
      "\n",
      "\n",
      "Conv1 = 332.061, Conv2 = 6842.833\n",
      "Dense1 = 118066.368, Dense2 = 1851.880 & O/p layer = 72.339\n",
      "Total number of parameters = 127165.481\n",
      "\n",
      "\n",
      "Conv1 = 298.855, Conv2 = 6158.550\n",
      "Dense1 = 94453.094, Dense2 = 1481.504 & O/p layer = 57.871\n",
      "Total number of parameters = 102449.874\n",
      "\n",
      "\n",
      "Conv1 = 268.970, Conv2 = 5542.695\n",
      "Dense1 = 75562.475, Dense2 = 1185.203 & O/p layer = 46.297\n",
      "Total number of parameters = 82605.640\n",
      "\n",
      "\n",
      "Conv1 = 242.073, Conv2 = 4988.425\n",
      "Dense1 = 60449.980, Dense2 = 948.163 & O/p layer = 37.038\n",
      "Total number of parameters = 66665.678\n",
      "\n",
      "\n",
      "Conv1 = 217.865, Conv2 = 4489.583\n",
      "Dense1 = 48359.984, Dense2 = 758.530 & O/p layer = 29.630\n",
      "Total number of parameters = 53855.593\n",
      "\n",
      "\n",
      "Conv1 = 196.079, Conv2 = 4040.624\n",
      "Dense1 = 38687.987, Dense2 = 606.824 & O/p layer = 23.704\n",
      "Total number of parameters = 43555.219\n",
      "\n",
      "\n",
      "Conv1 = 176.471, Conv2 = 3636.562\n",
      "Dense1 = 30950.390, Dense2 = 485.459 & O/p layer = 18.963\n",
      "Total number of parameters = 35267.845\n",
      "\n",
      "\n",
      "Conv1 = 158.824, Conv2 = 3272.906\n",
      "Dense1 = 24760.312, Dense2 = 388.367 & O/p layer = 15.171\n",
      "Total number of parameters = 28595.580\n",
      "\n",
      "\n",
      "Conv1 = 142.941, Conv2 = 2945.615\n",
      "Dense1 = 19808.250, Dense2 = 310.694 & O/p layer = 12.136\n",
      "Total number of parameters = 23219.637\n",
      "\n",
      "\n",
      "Conv1 = 128.647, Conv2 = 2651.054\n",
      "Dense1 = 15846.600, Dense2 = 248.555 & O/p layer = 9.709\n",
      "Total number of parameters = 18884.565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while loc_tot_params >= max_pruned_params:\n",
    "    loc_conv1 *= 0.9    # 10% weights are pruned\n",
    "    loc_conv2 *= 0.9    # 10% weights are pruned\n",
    "    loc_dense1 *= 0.8   # 20% weights are pruned\n",
    "    loc_dense2 *= 0.8   # 20% weights are pruned\n",
    "    loc_op_layer *= 0.8 # 20% weights are pruned\n",
    "    \n",
    "    conv1_pruning.append(((conv1 - loc_conv1) / conv1) * 100)\n",
    "    conv2_pruning.append(((conv2 - loc_conv2) / conv2) * 100)\n",
    "    dense1_pruning.append(((dense1 - loc_dense1) / dense1) * 100)\n",
    "    dense2_pruning.append(((dense2 - loc_dense2) / dense2) * 100)\n",
    "    op_layer_pruning.append(((op_layer - loc_op_layer) / op_layer) * 100)\n",
    "\n",
    "    loc_tot_params = loc_conv1 + loc_conv2 + loc_dense1 + loc_dense2 + loc_op_layer\n",
    "\n",
    "    n += 1\n",
    "\n",
    "    \n",
    "    print(\"\\nConv1 = {0:.3f}, Conv2 = {1:.3f}\".format(loc_conv1, loc_conv2))\n",
    "    print(\"Dense1 = {0:.3f}, Dense2 = {1:.3f} & O/p layer = {2:.3f}\".format(\n",
    "        loc_dense1, loc_dense2, loc_op_layer))\n",
    "    print(\"Total number of parameters = {0:.3f}\\n\".format(loc_tot_params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of pruning rounds = 25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nnumber of pruning rounds = {0}\\n\\n\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pruning_rounds = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from list to np.array-\n",
    "conv1_pruning = np.array(conv1_pruning)\n",
    "conv2_pruning = np.array(conv2_pruning)\n",
    "dense1_pruning = np.array(dense1_pruning)\n",
    "dense2_pruning = np.array(dense2_pruning)\n",
    "op_layer_pruning = np.array(op_layer_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round off numpy arrays to 3 decimal digits-\n",
    "conv1_pruning = np.round(conv1_pruning, decimals=3)\n",
    "conv2_pruning = np.round(conv2_pruning, decimals=3)\n",
    "dense1_pruning = np.round(dense1_pruning, decimals=3)\n",
    "dense2_pruning = np.round(dense2_pruning, decimals=3)\n",
    "op_layer_pruning = np.round(op_layer_pruning, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check-\n",
    "for i in range(6):\n",
    "    print(\"\\nconv1 = {0:.2f}, conv2 = {1:.2f}\".format(conv1_pruning[i], conv2_pruning[i]))\n",
    "    print(\"dense1 = {0:.2f}, dense2 = {1:.2f} & op = {2:.2f}\\n\".format(dense1_pruning[i], dense2_pruning[i], op_layer_pruning[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_pruning = conv1_pruning / 100\n",
    "conv2_pruning = conv2_pruning / 100\n",
    "dense1_pruning = dense1_pruning / 100\n",
    "dense2_pruning = dense2_pruning / 100\n",
    "op_layer_pruning = op_layer_pruning / 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2    , 0.36   , 0.488  , 0.5904 , 0.67232, 0.73786, 0.79028,\n",
       "       0.83223, 0.86578, 0.89263, 0.9141 , 0.93128, 0.94502, 0.95602,\n",
       "       0.96482, 0.97185, 0.97748, 0.98199, 0.98559, 0.98847, 0.99078,\n",
       "       0.99262, 0.9941 , 0.99528, 0.99622])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a mask:\n",
    "A mask is created where all parameters equal to one.\n",
    "\n",
    "This will be used later by _GradientTape_ for training the defined neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new neural network model for which, the mask is to be created,\n",
    "# according to the paper-\n",
    "mask_model = pruned_nn(pruning_params_unpruned, pruning_params_unpruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the model of its pruning parameters-\n",
    "mask_model_stripped = sparsity.strip_pruning(mask_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign all masks to one-\n",
    "\n",
    "for wts in mask_model_stripped.trainable_weights:\n",
    "    wts.assign(\n",
    "        tf.ones_like(\n",
    "            input = wts,\n",
    "            dtype = tf.float32\n",
    "        )\n",
    "\n",
    "    )\n",
    "    # wts.assign(1.)\n",
    "    # wts.assign(tf.where(tf.equal(wts, 0.), 0., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mask model metrics:\n",
      "layer-wise number of nonzero parameters in each layer are: \n",
      "\n",
      "1728\n",
      "64\n",
      "36864\n",
      "64\n",
      "4194304\n",
      "256\n",
      "65536\n",
      "256\n",
      "2560\n",
      "10\n",
      "\n",
      "Total number of trainable parameters = 4301642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMask model metrics:\")\n",
    "print(\"layer-wise number of nonzero parameters in each layer are: \\n\")\n",
    "\n",
    "masked_sum_params = 0\n",
    "\n",
    "for layer in mask_model_stripped.trainable_weights:\n",
    "    print(tf.math.count_nonzero(layer, axis = None).numpy())\n",
    "    masked_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "\n",
    "print(\"\\nTotal number of trainable parameters = {0}\\n\".format(masked_sum_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number of pruning rounds for Conv-2 CNN = 25 and number of epochs = 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nnumber of pruning rounds for Conv-2 CNN = {0} and number of epochs = {1}\\n\".format(num_pruning_rounds, num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python 3 dictionary to hold model training metrics for each of _n_ rounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method - 1: Nested Python 3 dictionaries:\n",
    "history_main = {}\n",
    "\n",
    "# for x in range(num_pruning_rounds + 1):\n",
    "for x in range(num_pruning_rounds):\n",
    "    history = {}\n",
    "    history['accuracy'] = np.zeros(shape = num_epochs)\n",
    "    history['val_accuracy'] = np.zeros(shape = num_epochs)\n",
    "    history['loss'] = np.zeros(shape = num_epochs)\n",
    "    history['val_loss'] = np.zeros(shape = num_epochs)\n",
    "\n",
    "    history_main[x + 1] = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "history_main.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "history_main[10]['accuracy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input parameters for Early Stopping in manual implementation-\n",
    "minimum_delta = 0.001\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = 100\n",
    "loc_patience = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 1\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.3794, Accuracy: 49.9120, Test Loss: 1.1332, Test Accuracy: 59.490002\n",
      "Total number of trainable parameters = 4301640\n",
      "\n",
      "Epoch 2, Loss: 1.0210, Accuracy: 63.7560, Test Loss: 0.9885, Test Accuracy: 65.120003\n",
      "Total number of trainable parameters = 4301640\n",
      "\n",
      "Epoch 3, Loss: 0.8740, Accuracy: 69.4600, Test Loss: 0.9806, Test Accuracy: 65.230003\n",
      "Total number of trainable parameters = 4301641\n",
      "\n",
      "Epoch 4, Loss: 0.7687, Accuracy: 72.9780, Test Loss: 0.9095, Test Accuracy: 68.159996\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "Epoch 5, Loss: 0.6794, Accuracy: 76.5160, Test Loss: 0.9020, Test Accuracy: 68.839996\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "Epoch 6, Loss: 0.5902, Accuracy: 79.5260, Test Loss: 0.8926, Test Accuracy: 69.950005\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "Epoch 7, Loss: 0.5009, Accuracy: 82.8980, Test Loss: 0.9208, Test Accuracy: 70.520004\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "Epoch 8, Loss: 0.4155, Accuracy: 85.9080, Test Loss: 0.9558, Test Accuracy: 69.580002\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "Epoch 9, Loss: 0.3312, Accuracy: 89.0420, Test Loss: 1.0088, Test Accuracy: 69.660004\n",
      "Total number of trainable parameters = 4301642\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 71s 1ms/sample - loss: 0.2576 - accuracy: 0.9165 - val_loss: 1.1068 - val_accuracy: 0.6951\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.1804 - accuracy: 0.9454 - val_loss: 1.1941 - val_accuracy: 0.6906\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.1277 - accuracy: 0.9634 - val_loss: 1.4194 - val_accuracy: 0.6855\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.0890 - accuracy: 0.9766 - val_loss: 1.4869 - val_accuracy: 0.6890\n",
      "\n",
      "Round = 1, total number of trainable parameters = 3445303\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 2\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.3228, Accuracy: 52.3440, Test Loss: 1.1469, Test Accuracy: 60.530003\n",
      "Total number of trainable parameters = 3445219\n",
      "\n",
      "Epoch 2, Loss: 0.9689, Accuracy: 65.8220, Test Loss: 0.9700, Test Accuracy: 65.869995\n",
      "Total number of trainable parameters = 3445242\n",
      "\n",
      "Epoch 3, Loss: 0.8391, Accuracy: 70.6540, Test Loss: 0.9306, Test Accuracy: 67.570000\n",
      "Total number of trainable parameters = 3445250\n",
      "\n",
      "Epoch 4, Loss: 0.7464, Accuracy: 74.1320, Test Loss: 0.9103, Test Accuracy: 68.510002\n",
      "Total number of trainable parameters = 3445257\n",
      "\n",
      "Epoch 5, Loss: 0.6725, Accuracy: 76.5620, Test Loss: 0.8897, Test Accuracy: 69.230003\n",
      "Total number of trainable parameters = 3445261\n",
      "\n",
      "Epoch 6, Loss: 0.5945, Accuracy: 79.6280, Test Loss: 0.8872, Test Accuracy: 69.870003\n",
      "Total number of trainable parameters = 3445263\n",
      "\n",
      "Epoch 7, Loss: 0.5207, Accuracy: 82.1840, Test Loss: 0.9332, Test Accuracy: 69.019997\n",
      "Total number of trainable parameters = 3445264\n",
      "\n",
      "Epoch 8, Loss: 0.4477, Accuracy: 84.9420, Test Loss: 0.9596, Test Accuracy: 69.309998\n",
      "Total number of trainable parameters = 3445267\n",
      "\n",
      "Epoch 9, Loss: 0.3719, Accuracy: 87.5140, Test Loss: 0.9899, Test Accuracy: 69.470001\n",
      "Total number of trainable parameters = 3445268\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.3027 - accuracy: 0.9006 - val_loss: 1.0928 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.2272 - accuracy: 0.9296 - val_loss: 1.1314 - val_accuracy: 0.6993\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.1678 - accuracy: 0.9512 - val_loss: 1.2409 - val_accuracy: 0.6960\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.1248 - accuracy: 0.9646 - val_loss: 1.3572 - val_accuracy: 0.6921\n",
      "\n",
      "Round = 2, total number of trainable parameters = 2759830\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 3\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.2715, Accuracy: 54.4360, Test Loss: 1.1124, Test Accuracy: 61.400002\n",
      "Total number of trainable parameters = 2759707\n",
      "\n",
      "Epoch 2, Loss: 0.9452, Accuracy: 66.9820, Test Loss: 0.9775, Test Accuracy: 65.699997\n",
      "Total number of trainable parameters = 2759716\n",
      "\n",
      "Epoch 3, Loss: 0.8261, Accuracy: 71.2520, Test Loss: 0.9159, Test Accuracy: 67.839996\n",
      "Total number of trainable parameters = 2759720\n",
      "\n",
      "Epoch 4, Loss: 0.7425, Accuracy: 74.1640, Test Loss: 0.9089, Test Accuracy: 68.599998\n",
      "Total number of trainable parameters = 2759722\n",
      "\n",
      "Epoch 5, Loss: 0.6702, Accuracy: 76.8820, Test Loss: 0.9037, Test Accuracy: 69.169998\n",
      "Total number of trainable parameters = 2759727\n",
      "\n",
      "Epoch 6, Loss: 0.5929, Accuracy: 79.7300, Test Loss: 0.9222, Test Accuracy: 68.510002\n",
      "Total number of trainable parameters = 2759730\n",
      "\n",
      "Epoch 7, Loss: 0.5239, Accuracy: 82.1040, Test Loss: 0.8978, Test Accuracy: 69.590004\n",
      "Total number of trainable parameters = 2759734\n",
      "\n",
      "Epoch 8, Loss: 0.4559, Accuracy: 84.6500, Test Loss: 0.9554, Test Accuracy: 69.570000\n",
      "Total number of trainable parameters = 2759736\n",
      "\n",
      "Epoch 9, Loss: 0.3892, Accuracy: 86.9960, Test Loss: 0.9718, Test Accuracy: 69.930000\n",
      "Total number of trainable parameters = 2759737\n",
      "\n",
      "Epoch 10, Loss: 0.3307, Accuracy: 89.0780, Test Loss: 1.0242, Test Accuracy: 69.959999\n",
      "Total number of trainable parameters = 2759739\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.2723 - accuracy: 0.9138 - val_loss: 1.1357 - val_accuracy: 0.6889\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.2129 - accuracy: 0.9346 - val_loss: 1.1484 - val_accuracy: 0.6961\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.1628 - accuracy: 0.9523 - val_loss: 1.2862 - val_accuracy: 0.6843\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.1249 - accuracy: 0.9656 - val_loss: 1.3712 - val_accuracy: 0.6931\n",
      "\n",
      "Round = 3, total number of trainable parameters = 2211106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 4\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.2298, Accuracy: 55.9500, Test Loss: 1.0449, Test Accuracy: 62.849998\n",
      "Total number of trainable parameters = 2210988\n",
      "\n",
      "Epoch 2, Loss: 0.9153, Accuracy: 68.0580, Test Loss: 0.9417, Test Accuracy: 67.089996\n",
      "Total number of trainable parameters = 2210998\n",
      "\n",
      "Epoch 3, Loss: 0.8072, Accuracy: 71.8320, Test Loss: 0.9081, Test Accuracy: 68.260002\n",
      "Total number of trainable parameters = 2211002\n",
      "\n",
      "Epoch 4, Loss: 0.7261, Accuracy: 74.8360, Test Loss: 0.8904, Test Accuracy: 69.080002\n",
      "Total number of trainable parameters = 2211008\n",
      "\n",
      "Epoch 5, Loss: 0.6561, Accuracy: 77.4060, Test Loss: 0.9353, Test Accuracy: 68.419998\n",
      "Total number of trainable parameters = 2211013\n",
      "\n",
      "Epoch 6, Loss: 0.5930, Accuracy: 79.5600, Test Loss: 0.8957, Test Accuracy: 69.660004\n",
      "Total number of trainable parameters = 2211025\n",
      "\n",
      "Epoch 7, Loss: 0.5303, Accuracy: 81.8760, Test Loss: 0.9290, Test Accuracy: 69.580002\n",
      "Total number of trainable parameters = 2211030\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.4725 - accuracy: 0.8402 - val_loss: 0.9365 - val_accuracy: 0.6995\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4205 - accuracy: 0.8600 - val_loss: 0.9664 - val_accuracy: 0.6958\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.3644 - accuracy: 0.8800 - val_loss: 1.0057 - val_accuracy: 0.6936\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.3143 - accuracy: 0.8990 - val_loss: 1.0489 - val_accuracy: 0.6979\n",
      "\n",
      "Round = 4, total number of trainable parameters = 1771804\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 5\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.1978, Accuracy: 57.5780, Test Loss: 1.0458, Test Accuracy: 63.290001\n",
      "Total number of trainable parameters = 1771698\n",
      "\n",
      "Epoch 2, Loss: 0.8948, Accuracy: 68.9620, Test Loss: 0.9318, Test Accuracy: 67.099998\n",
      "Total number of trainable parameters = 1771706\n",
      "\n",
      "Epoch 3, Loss: 0.7863, Accuracy: 72.8260, Test Loss: 0.9106, Test Accuracy: 68.029999\n",
      "Total number of trainable parameters = 1771709\n",
      "\n",
      "Epoch 4, Loss: 0.7076, Accuracy: 75.7000, Test Loss: 0.8855, Test Accuracy: 69.520004\n",
      "Total number of trainable parameters = 1771712\n",
      "\n",
      "Epoch 5, Loss: 0.6358, Accuracy: 78.1300, Test Loss: 0.8919, Test Accuracy: 69.450005\n",
      "Total number of trainable parameters = 1771715\n",
      "\n",
      "Epoch 6, Loss: 0.5693, Accuracy: 80.5360, Test Loss: 0.8919, Test Accuracy: 70.099998\n",
      "Total number of trainable parameters = 1771717\n",
      "\n",
      "Epoch 7, Loss: 0.5039, Accuracy: 82.8620, Test Loss: 0.9045, Test Accuracy: 70.110001\n",
      "Total number of trainable parameters = 1771719\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.4432 - accuracy: 0.8521 - val_loss: 0.9379 - val_accuracy: 0.7027\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3945 - accuracy: 0.8712 - val_loss: 0.9552 - val_accuracy: 0.7007\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3343 - accuracy: 0.8934 - val_loss: 1.0339 - val_accuracy: 0.6975\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.2863 - accuracy: 0.9104 - val_loss: 1.0548 - val_accuracy: 0.6987\n",
      "\n",
      "Round = 5, total number of trainable parameters = 1420073\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 6\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.1793, Accuracy: 58.3980, Test Loss: 1.0174, Test Accuracy: 63.950001\n",
      "Total number of trainable parameters = 1419998\n",
      "\n",
      "Epoch 2, Loss: 0.8704, Accuracy: 69.8460, Test Loss: 0.9419, Test Accuracy: 67.239998\n",
      "Total number of trainable parameters = 1420010\n",
      "\n",
      "Epoch 3, Loss: 0.7586, Accuracy: 73.7600, Test Loss: 0.8939, Test Accuracy: 69.010002\n",
      "Total number of trainable parameters = 1420017\n",
      "\n",
      "Epoch 4, Loss: 0.6725, Accuracy: 76.7100, Test Loss: 0.8870, Test Accuracy: 69.470001\n",
      "Total number of trainable parameters = 1420020\n",
      "\n",
      "Epoch 5, Loss: 0.5985, Accuracy: 79.6520, Test Loss: 0.8958, Test Accuracy: 69.120003\n",
      "Total number of trainable parameters = 1420023\n",
      "\n",
      "Epoch 6, Loss: 0.5322, Accuracy: 82.1320, Test Loss: 0.8886, Test Accuracy: 69.880005\n",
      "Total number of trainable parameters = 1420024\n",
      "\n",
      "Epoch 7, Loss: 0.4709, Accuracy: 84.2600, Test Loss: 0.9291, Test Accuracy: 69.900002\n",
      "Total number of trainable parameters = 1420025\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.4106 - accuracy: 0.8639 - val_loss: 0.9377 - val_accuracy: 0.7001\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.3718 - accuracy: 0.8814 - val_loss: 0.9925 - val_accuracy: 0.6958\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3169 - accuracy: 0.9005 - val_loss: 1.0214 - val_accuracy: 0.6934\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.2742 - accuracy: 0.9152 - val_loss: 1.0822 - val_accuracy: 0.6952\n",
      "\n",
      "Round = 6, total number of trainable parameters = 1138434\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 7\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.1685, Accuracy: 59.0240, Test Loss: 1.0321, Test Accuracy: 64.410004\n",
      "Total number of trainable parameters = 1138363\n",
      "\n",
      "Epoch 2, Loss: 0.8698, Accuracy: 69.9520, Test Loss: 0.9266, Test Accuracy: 67.619995\n",
      "Total number of trainable parameters = 1138371\n",
      "\n",
      "Epoch 3, Loss: 0.7566, Accuracy: 73.9980, Test Loss: 0.9044, Test Accuracy: 68.449997\n",
      "Total number of trainable parameters = 1138374\n",
      "\n",
      "Epoch 4, Loss: 0.6750, Accuracy: 76.6920, Test Loss: 0.8817, Test Accuracy: 69.669998\n",
      "Total number of trainable parameters = 1138374\n",
      "\n",
      "Epoch 5, Loss: 0.6022, Accuracy: 79.4840, Test Loss: 0.9228, Test Accuracy: 68.750000\n",
      "Total number of trainable parameters = 1138375\n",
      "\n",
      "Epoch 6, Loss: 0.5422, Accuracy: 81.5840, Test Loss: 0.8951, Test Accuracy: 69.680000\n",
      "Total number of trainable parameters = 1138380\n",
      "\n",
      "Epoch 7, Loss: 0.4847, Accuracy: 83.6960, Test Loss: 0.9349, Test Accuracy: 69.700005\n",
      "Total number of trainable parameters = 1138382\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.4320 - accuracy: 0.8554 - val_loss: 0.9629 - val_accuracy: 0.6933\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.4068 - accuracy: 0.8658 - val_loss: 0.9446 - val_accuracy: 0.7056\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3536 - accuracy: 0.8853 - val_loss: 1.0060 - val_accuracy: 0.6935\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3089 - accuracy: 0.9020 - val_loss: 1.0393 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.2732 - accuracy: 0.9137 - val_loss: 1.0912 - val_accuracy: 0.6916\n",
      "\n",
      "Round = 7, total number of trainable parameters = 912927\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 8\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.1771, Accuracy: 58.6260, Test Loss: 1.0133, Test Accuracy: 64.650002\n",
      "Total number of trainable parameters = 912859\n",
      "\n",
      "Epoch 2, Loss: 0.8694, Accuracy: 70.1080, Test Loss: 0.9530, Test Accuracy: 66.900002\n",
      "Total number of trainable parameters = 912863\n",
      "\n",
      "Epoch 3, Loss: 0.7523, Accuracy: 73.9960, Test Loss: 0.9021, Test Accuracy: 68.129997\n",
      "Total number of trainable parameters = 912864\n",
      "\n",
      "Epoch 4, Loss: 0.6672, Accuracy: 77.0100, Test Loss: 0.8713, Test Accuracy: 69.660004\n",
      "Total number of trainable parameters = 912865\n",
      "\n",
      "Epoch 5, Loss: 0.5963, Accuracy: 79.5700, Test Loss: 0.8933, Test Accuracy: 69.639999\n",
      "Total number of trainable parameters = 912867\n",
      "\n",
      "Epoch 6, Loss: 0.5368, Accuracy: 81.6480, Test Loss: 0.9090, Test Accuracy: 69.570000\n",
      "Total number of trainable parameters = 912868\n",
      "\n",
      "Epoch 7, Loss: 0.4805, Accuracy: 83.7460, Test Loss: 0.9142, Test Accuracy: 69.770004\n",
      "Total number of trainable parameters = 912869\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 73s 1ms/sample - loss: 0.4328 - accuracy: 0.8561 - val_loss: 0.9494 - val_accuracy: 0.6975\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.4186 - accuracy: 0.8639 - val_loss: 0.9395 - val_accuracy: 0.7021\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3658 - accuracy: 0.8819 - val_loss: 0.9958 - val_accuracy: 0.6942\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3269 - accuracy: 0.8950 - val_loss: 1.0371 - val_accuracy: 0.6961\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.2925 - accuracy: 0.9078 - val_loss: 1.0537 - val_accuracy: 0.6975\n",
      "\n",
      "Round = 8, total number of trainable parameters = 732245\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 9\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.1853, Accuracy: 58.8780, Test Loss: 1.0200, Test Accuracy: 64.349998\n",
      "Total number of trainable parameters = 732195\n",
      "\n",
      "Epoch 2, Loss: 0.8805, Accuracy: 69.6680, Test Loss: 0.9938, Test Accuracy: 65.240005\n",
      "Total number of trainable parameters = 732201\n",
      "\n",
      "Epoch 3, Loss: 0.7652, Accuracy: 73.6460, Test Loss: 0.9078, Test Accuracy: 68.019997\n",
      "Total number of trainable parameters = 732205\n",
      "\n",
      "Epoch 4, Loss: 0.6821, Accuracy: 76.6760, Test Loss: 0.8834, Test Accuracy: 69.300003\n",
      "Total number of trainable parameters = 732207\n",
      "\n",
      "Epoch 5, Loss: 0.6147, Accuracy: 79.0500, Test Loss: 0.8964, Test Accuracy: 68.809998\n",
      "Total number of trainable parameters = 732208\n",
      "\n",
      "Epoch 6, Loss: 0.5552, Accuracy: 81.1600, Test Loss: 0.9021, Test Accuracy: 69.230003\n",
      "Total number of trainable parameters = 732209\n",
      "\n",
      "Epoch 7, Loss: 0.5059, Accuracy: 82.7860, Test Loss: 0.9065, Test Accuracy: 69.750000\n",
      "Total number of trainable parameters = 732209\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.4565 - accuracy: 0.8461 - val_loss: 0.9340 - val_accuracy: 0.7008\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4542 - accuracy: 0.8508 - val_loss: 0.9362 - val_accuracy: 0.6965\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4056 - accuracy: 0.8669 - val_loss: 0.9719 - val_accuracy: 0.6947\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.3669 - accuracy: 0.8806 - val_loss: 0.9875 - val_accuracy: 0.6962\n",
      "\n",
      "Round = 9, total number of trainable parameters = 587577\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 10\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.2082, Accuracy: 57.8800, Test Loss: 1.0387, Test Accuracy: 63.750000\n",
      "Total number of trainable parameters = 587514\n",
      "\n",
      "Epoch 2, Loss: 0.8998, Accuracy: 68.9480, Test Loss: 0.9567, Test Accuracy: 66.509995\n",
      "Total number of trainable parameters = 587527\n",
      "\n",
      "Epoch 3, Loss: 0.7801, Accuracy: 73.1260, Test Loss: 0.9296, Test Accuracy: 67.500000\n",
      "Total number of trainable parameters = 587530\n",
      "\n",
      "Epoch 4, Loss: 0.7002, Accuracy: 75.7840, Test Loss: 0.9212, Test Accuracy: 67.720001\n",
      "Total number of trainable parameters = 587530\n",
      "\n",
      "Epoch 5, Loss: 0.6368, Accuracy: 78.1620, Test Loss: 0.9065, Test Accuracy: 69.129997\n",
      "Total number of trainable parameters = 587531\n",
      "\n",
      "Epoch 6, Loss: 0.5826, Accuracy: 80.1920, Test Loss: 0.9075, Test Accuracy: 69.070000\n",
      "Total number of trainable parameters = 587533\n",
      "\n",
      "Epoch 7, Loss: 0.5338, Accuracy: 81.9060, Test Loss: 0.9067, Test Accuracy: 69.489998\n",
      "Total number of trainable parameters = 587533\n",
      "\n",
      "Epoch 8, Loss: 0.4893, Accuracy: 83.5200, Test Loss: 0.9263, Test Accuracy: 69.639999\n",
      "Total number of trainable parameters = 587535\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 72s 1ms/sample - loss: 0.4486 - accuracy: 0.8510 - val_loss: 0.9551 - val_accuracy: 0.6959\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.4592 - accuracy: 0.8493 - val_loss: 0.9332 - val_accuracy: 0.6991\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.4071 - accuracy: 0.8680 - val_loss: 0.9809 - val_accuracy: 0.6941\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3725 - accuracy: 0.8803 - val_loss: 0.9855 - val_accuracy: 0.6927\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3414 - accuracy: 0.8902 - val_loss: 1.0368 - val_accuracy: 0.6936\n",
      "\n",
      "Round = 10, total number of trainable parameters = 471618\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 11\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.2422, Accuracy: 56.5500, Test Loss: 1.0965, Test Accuracy: 61.659996\n",
      "Total number of trainable parameters = 471557\n",
      "\n",
      "Epoch 2, Loss: 0.9313, Accuracy: 67.7200, Test Loss: 0.9701, Test Accuracy: 66.449997\n",
      "Total number of trainable parameters = 471563\n",
      "\n",
      "Epoch 3, Loss: 0.8127, Accuracy: 72.0000, Test Loss: 0.9373, Test Accuracy: 67.400002\n",
      "Total number of trainable parameters = 471566\n",
      "\n",
      "Epoch 4, Loss: 0.7290, Accuracy: 74.9400, Test Loss: 0.8997, Test Accuracy: 68.860001\n",
      "Total number of trainable parameters = 471567\n",
      "\n",
      "Epoch 5, Loss: 0.6624, Accuracy: 77.1880, Test Loss: 0.8963, Test Accuracy: 69.559998\n",
      "Total number of trainable parameters = 471568\n",
      "\n",
      "Epoch 6, Loss: 0.6094, Accuracy: 79.1540, Test Loss: 0.8945, Test Accuracy: 69.300003\n",
      "Total number of trainable parameters = 471568\n",
      "\n",
      "Epoch 7, Loss: 0.5620, Accuracy: 80.8320, Test Loss: 0.9030, Test Accuracy: 69.930000\n",
      "Total number of trainable parameters = 471568\n",
      "\n",
      "Epoch 8, Loss: 0.5213, Accuracy: 82.2320, Test Loss: 0.9335, Test Accuracy: 68.910004\n",
      "Total number of trainable parameters = 471569\n",
      "\n",
      "Epoch 9, Loss: 0.4822, Accuracy: 83.8020, Test Loss: 0.9282, Test Accuracy: 70.320000\n",
      "Total number of trainable parameters = 471570\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.4481 - accuracy: 0.8504 - val_loss: 0.9562 - val_accuracy: 0.6988\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.4687 - accuracy: 0.8466 - val_loss: 0.9499 - val_accuracy: 0.6914\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4154 - accuracy: 0.8653 - val_loss: 0.9719 - val_accuracy: 0.6938\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.3843 - accuracy: 0.8760 - val_loss: 0.9905 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.3553 - accuracy: 0.8864 - val_loss: 1.0194 - val_accuracy: 0.6953\n",
      "\n",
      "Round = 11, total number of trainable parameters = 378735\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 12\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.2816, Accuracy: 55.4960, Test Loss: 1.0875, Test Accuracy: 62.190002\n",
      "Total number of trainable parameters = 378676\n",
      "\n",
      "Epoch 2, Loss: 0.9586, Accuracy: 66.9600, Test Loss: 1.0042, Test Accuracy: 64.430000\n",
      "Total number of trainable parameters = 378681\n",
      "\n",
      "Epoch 3, Loss: 0.8418, Accuracy: 71.1320, Test Loss: 0.9431, Test Accuracy: 67.110001\n",
      "Total number of trainable parameters = 378686\n",
      "\n",
      "Epoch 4, Loss: 0.7566, Accuracy: 73.9680, Test Loss: 0.9268, Test Accuracy: 68.019997\n",
      "Total number of trainable parameters = 378686\n",
      "\n",
      "Epoch 5, Loss: 0.6918, Accuracy: 76.2940, Test Loss: 0.9068, Test Accuracy: 68.680000\n",
      "Total number of trainable parameters = 378688\n",
      "\n",
      "Epoch 6, Loss: 0.6383, Accuracy: 78.2180, Test Loss: 0.9335, Test Accuracy: 67.820000\n",
      "Total number of trainable parameters = 378691\n",
      "\n",
      "Epoch 7, Loss: 0.5909, Accuracy: 79.7300, Test Loss: 0.9162, Test Accuracy: 68.779999\n",
      "Total number of trainable parameters = 378692\n",
      "\n",
      "Epoch 8, Loss: 0.5506, Accuracy: 81.2720, Test Loss: 0.9121, Test Accuracy: 69.730003\n",
      "Total number of trainable parameters = 378693\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.5129 - accuracy: 0.8265 - val_loss: 0.9254 - val_accuracy: 0.6941\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.5386 - accuracy: 0.8223 - val_loss: 0.9155 - val_accuracy: 0.6911\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.4885 - accuracy: 0.8375 - val_loss: 0.9377 - val_accuracy: 0.6919\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.4566 - accuracy: 0.8480 - val_loss: 0.9602 - val_accuracy: 0.6915\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.4276 - accuracy: 0.8587 - val_loss: 0.9619 - val_accuracy: 0.6979\n",
      "\n",
      "Round = 12, total number of trainable parameters = 304277\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 13\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.3379, Accuracy: 53.2920, Test Loss: 1.1353, Test Accuracy: 59.920002\n",
      "Total number of trainable parameters = 304222\n",
      "\n",
      "Epoch 2, Loss: 1.0172, Accuracy: 64.8880, Test Loss: 1.0360, Test Accuracy: 63.790001\n",
      "Total number of trainable parameters = 304225\n",
      "\n",
      "Epoch 3, Loss: 0.9009, Accuracy: 68.7180, Test Loss: 0.9759, Test Accuracy: 66.099998\n",
      "Total number of trainable parameters = 304229\n",
      "\n",
      "Epoch 4, Loss: 0.8179, Accuracy: 71.7940, Test Loss: 0.9410, Test Accuracy: 67.430000\n",
      "Total number of trainable parameters = 304231\n",
      "\n",
      "Epoch 5, Loss: 0.7505, Accuracy: 74.1560, Test Loss: 0.9240, Test Accuracy: 68.180000\n",
      "Total number of trainable parameters = 304232\n",
      "\n",
      "Epoch 6, Loss: 0.6978, Accuracy: 75.9600, Test Loss: 0.9132, Test Accuracy: 68.660004\n",
      "Total number of trainable parameters = 304232\n",
      "\n",
      "Epoch 7, Loss: 0.6483, Accuracy: 77.6520, Test Loss: 0.9152, Test Accuracy: 68.680000\n",
      "Total number of trainable parameters = 304232\n",
      "\n",
      "Epoch 8, Loss: 0.6099, Accuracy: 78.9980, Test Loss: 0.9181, Test Accuracy: 68.820000\n",
      "Total number of trainable parameters = 304232\n",
      "\n",
      "Epoch 9, Loss: 0.5734, Accuracy: 80.3340, Test Loss: 0.9246, Test Accuracy: 68.910004\n",
      "Total number of trainable parameters = 304232\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.5405 - accuracy: 0.8158 - val_loss: 0.9324 - val_accuracy: 0.6897\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.5782 - accuracy: 0.8066 - val_loss: 0.9189 - val_accuracy: 0.6907\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.5243 - accuracy: 0.8234 - val_loss: 0.9317 - val_accuracy: 0.6902\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4913 - accuracy: 0.8342 - val_loss: 0.9478 - val_accuracy: 0.6886\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4636 - accuracy: 0.8455 - val_loss: 0.9569 - val_accuracy: 0.6922\n",
      "\n",
      "Round = 13, total number of trainable parameters = 244603\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 14\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.3917, Accuracy: 51.3860, Test Loss: 1.1714, Test Accuracy: 58.910000\n",
      "Total number of trainable parameters = 244549\n",
      "\n",
      "Epoch 2, Loss: 1.0551, Accuracy: 63.4280, Test Loss: 1.0593, Test Accuracy: 62.750000\n",
      "Total number of trainable parameters = 244550\n",
      "\n",
      "Epoch 3, Loss: 0.9359, Accuracy: 67.5920, Test Loss: 0.9942, Test Accuracy: 65.389999\n",
      "Total number of trainable parameters = 244552\n",
      "\n",
      "Epoch 4, Loss: 0.8539, Accuracy: 70.5900, Test Loss: 0.9664, Test Accuracy: 66.139999\n",
      "Total number of trainable parameters = 244553\n",
      "\n",
      "Epoch 5, Loss: 0.7923, Accuracy: 72.6260, Test Loss: 0.9387, Test Accuracy: 67.349998\n",
      "Total number of trainable parameters = 244556\n",
      "\n",
      "Epoch 6, Loss: 0.7408, Accuracy: 74.3880, Test Loss: 0.9208, Test Accuracy: 68.019997\n",
      "Total number of trainable parameters = 244559\n",
      "\n",
      "Epoch 7, Loss: 0.6966, Accuracy: 75.8600, Test Loss: 0.9329, Test Accuracy: 67.989998\n",
      "Total number of trainable parameters = 244561\n",
      "\n",
      "Epoch 8, Loss: 0.6607, Accuracy: 77.2420, Test Loss: 0.9250, Test Accuracy: 68.370003\n",
      "Total number of trainable parameters = 244562\n",
      "\n",
      "Epoch 9, Loss: 0.6250, Accuracy: 78.4800, Test Loss: 0.9151, Test Accuracy: 68.860001\n",
      "Total number of trainable parameters = 244563\n",
      "\n",
      "Epoch 10, Loss: 0.5949, Accuracy: 79.4820, Test Loss: 0.9175, Test Accuracy: 68.959999\n",
      "Total number of trainable parameters = 244563\n",
      "\n",
      "Epoch 11, Loss: 0.5660, Accuracy: 80.6540, Test Loss: 0.9419, Test Accuracy: 68.440002\n",
      "Total number of trainable parameters = 244563\n",
      "\n",
      "Epoch 12, Loss: 0.5414, Accuracy: 81.4920, Test Loss: 0.9341, Test Accuracy: 69.050003\n",
      "Total number of trainable parameters = 244564\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.5165 - accuracy: 0.8236 - val_loss: 0.9480 - val_accuracy: 0.6946\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.5559 - accuracy: 0.8162 - val_loss: 0.9279 - val_accuracy: 0.6892\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.5045 - accuracy: 0.8320 - val_loss: 0.9378 - val_accuracy: 0.6917\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.4781 - accuracy: 0.8394 - val_loss: 0.9532 - val_accuracy: 0.6921\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.4542 - accuracy: 0.8494 - val_loss: 0.9694 - val_accuracy: 0.6927\n",
      "\n",
      "Round = 14, total number of trainable parameters = 196739\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 15\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.4469, Accuracy: 49.3720, Test Loss: 1.2321, Test Accuracy: 56.910004\n",
      "Total number of trainable parameters = 196669\n",
      "\n",
      "Epoch 2, Loss: 1.1141, Accuracy: 61.6200, Test Loss: 1.0975, Test Accuracy: 61.199997\n",
      "Total number of trainable parameters = 196670\n",
      "\n",
      "Epoch 3, Loss: 0.9949, Accuracy: 65.7380, Test Loss: 1.0367, Test Accuracy: 63.630001\n",
      "Total number of trainable parameters = 196673\n",
      "\n",
      "Epoch 4, Loss: 0.9128, Accuracy: 68.3560, Test Loss: 1.0069, Test Accuracy: 64.690002\n",
      "Total number of trainable parameters = 196673\n",
      "\n",
      "Epoch 5, Loss: 0.8520, Accuracy: 70.4060, Test Loss: 0.9654, Test Accuracy: 66.259995\n",
      "Total number of trainable parameters = 196675\n",
      "\n",
      "Epoch 6, Loss: 0.8022, Accuracy: 72.1660, Test Loss: 0.9572, Test Accuracy: 66.799995\n",
      "Total number of trainable parameters = 196676\n",
      "\n",
      "Epoch 7, Loss: 0.7596, Accuracy: 73.6400, Test Loss: 0.9400, Test Accuracy: 67.889999\n",
      "Total number of trainable parameters = 196678\n",
      "\n",
      "Epoch 8, Loss: 0.7216, Accuracy: 75.0340, Test Loss: 0.9276, Test Accuracy: 68.029999\n",
      "Total number of trainable parameters = 196679\n",
      "\n",
      "Epoch 9, Loss: 0.6872, Accuracy: 76.2840, Test Loss: 0.9232, Test Accuracy: 68.260002\n",
      "Total number of trainable parameters = 196681\n",
      "\n",
      "Epoch 10, Loss: 0.6578, Accuracy: 77.2060, Test Loss: 0.9222, Test Accuracy: 68.580002\n",
      "Total number of trainable parameters = 196681\n",
      "\n",
      "Epoch 11, Loss: 0.6297, Accuracy: 78.2940, Test Loss: 0.9314, Test Accuracy: 68.709999\n",
      "Total number of trainable parameters = 196681\n",
      "\n",
      "Epoch 12, Loss: 0.6044, Accuracy: 79.2800, Test Loss: 0.9245, Test Accuracy: 68.989998\n",
      "Total number of trainable parameters = 196685\n",
      "\n",
      "Epoch 13, Loss: 0.5790, Accuracy: 80.1640, Test Loss: 0.9373, Test Accuracy: 68.720001\n",
      "Total number of trainable parameters = 196685\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.5561 - accuracy: 0.8113 - val_loss: 0.9394 - val_accuracy: 0.6915\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.9370 - accuracy: 0.6495 - val_loss: 1.1319 - val_accuracy: 0.6171\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.8486 - accuracy: 0.7212 - val_loss: 1.0820 - val_accuracy: 0.6453\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.7747 - accuracy: 0.7563 - val_loss: 1.0756 - val_accuracy: 0.6518\n",
      "\n",
      "Round = 15, total number of trainable parameters = 158379\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 16\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.6282, Accuracy: 42.9720, Test Loss: 1.4041, Test Accuracy: 52.240002\n",
      "Total number of trainable parameters = 158306\n",
      "\n",
      "Epoch 2, Loss: 1.2994, Accuracy: 56.2580, Test Loss: 1.2665, Test Accuracy: 56.840004\n",
      "Total number of trainable parameters = 158311\n",
      "\n",
      "Epoch 3, Loss: 1.1645, Accuracy: 61.0760, Test Loss: 1.1768, Test Accuracy: 60.310001\n",
      "Total number of trainable parameters = 158318\n",
      "\n",
      "Epoch 4, Loss: 1.0705, Accuracy: 64.1560, Test Loss: 1.1276, Test Accuracy: 61.610001\n",
      "Total number of trainable parameters = 158320\n",
      "\n",
      "Epoch 5, Loss: 0.9952, Accuracy: 66.8600, Test Loss: 1.0781, Test Accuracy: 63.169998\n",
      "Total number of trainable parameters = 158323\n",
      "\n",
      "Epoch 6, Loss: 0.9366, Accuracy: 68.5060, Test Loss: 1.0605, Test Accuracy: 63.650002\n",
      "Total number of trainable parameters = 158325\n",
      "\n",
      "Epoch 7, Loss: 0.8845, Accuracy: 70.2860, Test Loss: 1.0347, Test Accuracy: 64.610001\n",
      "Total number of trainable parameters = 158326\n",
      "\n",
      "Epoch 8, Loss: 0.8409, Accuracy: 71.8460, Test Loss: 0.9962, Test Accuracy: 65.760002\n",
      "Total number of trainable parameters = 158326\n",
      "\n",
      "Epoch 9, Loss: 0.8019, Accuracy: 72.9600, Test Loss: 0.9815, Test Accuracy: 66.900002\n",
      "Total number of trainable parameters = 158327\n",
      "\n",
      "Epoch 10, Loss: 0.7670, Accuracy: 74.1720, Test Loss: 0.9696, Test Accuracy: 67.059998\n",
      "Total number of trainable parameters = 158327\n",
      "\n",
      "Epoch 11, Loss: 0.7366, Accuracy: 75.1280, Test Loss: 0.9756, Test Accuracy: 67.180000\n",
      "Total number of trainable parameters = 158327\n",
      "\n",
      "Epoch 12, Loss: 0.7085, Accuracy: 76.0040, Test Loss: 0.9689, Test Accuracy: 67.079994\n",
      "Total number of trainable parameters = 158328\n",
      "\n",
      "Epoch 13, Loss: 0.6815, Accuracy: 76.8960, Test Loss: 0.9721, Test Accuracy: 67.559998\n",
      "Total number of trainable parameters = 158329\n",
      "\n",
      "Epoch 14, Loss: 0.6579, Accuracy: 77.6700, Test Loss: 0.9720, Test Accuracy: 67.500000\n",
      "Total number of trainable parameters = 158329\n",
      "\n",
      "Epoch 15, Loss: 0.6340, Accuracy: 78.6660, Test Loss: 0.9595, Test Accuracy: 68.059998\n",
      "Total number of trainable parameters = 158330\n",
      "\n",
      "Epoch 16, Loss: 0.6119, Accuracy: 79.4000, Test Loss: 0.9738, Test Accuracy: 67.750000\n",
      "Total number of trainable parameters = 158330\n",
      "\n",
      "Epoch 17, Loss: 0.5909, Accuracy: 80.0040, Test Loss: 0.9637, Test Accuracy: 67.930000\n",
      "Total number of trainable parameters = 158331\n",
      "\n",
      "Epoch 18, Loss: 0.5706, Accuracy: 80.8200, Test Loss: 0.9669, Test Accuracy: 67.970001\n",
      "Total number of trainable parameters = 158331\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.5511 - accuracy: 0.8147 - val_loss: 0.9709 - val_accuracy: 0.6827\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.9913 - accuracy: 0.6930 - val_loss: 1.1803 - val_accuracy: 0.6272\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.8797 - accuracy: 0.7423 - val_loss: 1.1129 - val_accuracy: 0.6510\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.7878 - accuracy: 0.7682 - val_loss: 1.0685 - val_accuracy: 0.6598\n",
      "\n",
      "Round = 16, total number of trainable parameters = 127572\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 17\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.7467, Accuracy: 37.6540, Test Loss: 1.5157, Test Accuracy: 48.200001\n",
      "Total number of trainable parameters = 127511\n",
      "\n",
      "Epoch 2, Loss: 1.3818, Accuracy: 52.8220, Test Loss: 1.3298, Test Accuracy: 54.700001\n",
      "Total number of trainable parameters = 127513\n",
      "\n",
      "Epoch 3, Loss: 1.2319, Accuracy: 58.5620, Test Loss: 1.2307, Test Accuracy: 58.759998\n",
      "Total number of trainable parameters = 127513\n",
      "\n",
      "Epoch 4, Loss: 1.1310, Accuracy: 62.3340, Test Loss: 1.1655, Test Accuracy: 60.849998\n",
      "Total number of trainable parameters = 127515\n",
      "\n",
      "Epoch 5, Loss: 1.0527, Accuracy: 65.0280, Test Loss: 1.1236, Test Accuracy: 61.720001\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 6, Loss: 0.9891, Accuracy: 67.3520, Test Loss: 1.0893, Test Accuracy: 63.129997\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 7, Loss: 0.9383, Accuracy: 68.7360, Test Loss: 1.0675, Test Accuracy: 64.029999\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 8, Loss: 0.8944, Accuracy: 70.1380, Test Loss: 1.0411, Test Accuracy: 64.420006\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 9, Loss: 0.8566, Accuracy: 71.3100, Test Loss: 1.0238, Test Accuracy: 65.360001\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 10, Loss: 0.8224, Accuracy: 72.3940, Test Loss: 1.0147, Test Accuracy: 65.589996\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 11, Loss: 0.7942, Accuracy: 73.2480, Test Loss: 0.9963, Test Accuracy: 65.760002\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 12, Loss: 0.7684, Accuracy: 74.1840, Test Loss: 0.9898, Test Accuracy: 66.729996\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 13, Loss: 0.7418, Accuracy: 75.0180, Test Loss: 0.9877, Test Accuracy: 66.930000\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 14, Loss: 0.7194, Accuracy: 75.8180, Test Loss: 0.9935, Test Accuracy: 66.919998\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 15, Loss: 0.6976, Accuracy: 76.4020, Test Loss: 0.9853, Test Accuracy: 67.279999\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 16, Loss: 0.6782, Accuracy: 77.0700, Test Loss: 0.9771, Test Accuracy: 67.129997\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 17, Loss: 0.6571, Accuracy: 77.9640, Test Loss: 0.9747, Test Accuracy: 67.809998\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 18, Loss: 0.6397, Accuracy: 78.4440, Test Loss: 0.9759, Test Accuracy: 67.570000\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 19, Loss: 0.6222, Accuracy: 79.0480, Test Loss: 1.0005, Test Accuracy: 67.659996\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "Epoch 20, Loss: 0.6066, Accuracy: 79.6640, Test Loss: 0.9809, Test Accuracy: 67.989998\n",
      "Total number of trainable parameters = 127516\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.5897 - accuracy: 0.8018 - val_loss: 0.9913 - val_accuracy: 0.6801\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 1.0638 - accuracy: 0.6917 - val_loss: 1.2665 - val_accuracy: 0.6072\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.9981 - accuracy: 0.7223 - val_loss: 1.2040 - val_accuracy: 0.6261\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.9124 - accuracy: 0.7482 - val_loss: 1.1484 - val_accuracy: 0.6474\n",
      "\n",
      "Round = 17, total number of trainable parameters = 102804\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 18\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.9092, Accuracy: 34.2500, Test Loss: 1.7359, Test Accuracy: 44.020000\n",
      "Total number of trainable parameters = 102766\n",
      "\n",
      "Epoch 2, Loss: 1.6380, Accuracy: 50.3880, Test Loss: 1.5697, Test Accuracy: 52.840000\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 3, Loss: 1.4858, Accuracy: 56.5020, Test Loss: 1.4637, Test Accuracy: 55.299995\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 4, Loss: 1.3639, Accuracy: 60.4740, Test Loss: 1.3694, Test Accuracy: 58.429996\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 5, Loss: 1.2615, Accuracy: 63.4980, Test Loss: 1.2949, Test Accuracy: 61.099998\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 6, Loss: 1.1738, Accuracy: 65.8020, Test Loss: 1.2322, Test Accuracy: 62.440002\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 7, Loss: 1.0988, Accuracy: 67.5940, Test Loss: 1.1814, Test Accuracy: 63.480003\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 8, Loss: 1.0365, Accuracy: 69.0760, Test Loss: 1.1435, Test Accuracy: 64.300003\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 9, Loss: 0.9803, Accuracy: 70.4660, Test Loss: 1.1102, Test Accuracy: 64.790001\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 10, Loss: 0.9309, Accuracy: 71.6840, Test Loss: 1.0898, Test Accuracy: 66.059998\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 11, Loss: 0.8888, Accuracy: 72.7860, Test Loss: 1.0584, Test Accuracy: 66.180000\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 12, Loss: 0.8517, Accuracy: 73.6980, Test Loss: 1.0448, Test Accuracy: 66.579994\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 13, Loss: 0.8168, Accuracy: 74.5800, Test Loss: 1.0459, Test Accuracy: 66.759995\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 14, Loss: 0.7876, Accuracy: 75.2720, Test Loss: 1.0175, Test Accuracy: 67.320000\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 15, Loss: 0.7606, Accuracy: 76.1440, Test Loss: 1.0174, Test Accuracy: 67.650002\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 16, Loss: 0.7353, Accuracy: 76.7940, Test Loss: 1.0224, Test Accuracy: 67.199997\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 17, Loss: 0.7126, Accuracy: 77.5180, Test Loss: 1.0050, Test Accuracy: 66.939995\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 18, Loss: 0.6914, Accuracy: 77.9140, Test Loss: 0.9969, Test Accuracy: 67.860001\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 19, Loss: 0.6714, Accuracy: 78.6740, Test Loss: 1.0049, Test Accuracy: 67.849998\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 20, Loss: 0.6516, Accuracy: 79.3320, Test Loss: 0.9962, Test Accuracy: 68.180000\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 21, Loss: 0.6350, Accuracy: 79.7120, Test Loss: 0.9976, Test Accuracy: 67.659996\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 22, Loss: 0.6186, Accuracy: 80.3340, Test Loss: 1.0025, Test Accuracy: 68.250000\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "Epoch 23, Loss: 0.6032, Accuracy: 80.6400, Test Loss: 1.0049, Test Accuracy: 68.239998\n",
      "Total number of trainable parameters = 102767\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 0.5882 - accuracy: 0.8122 - val_loss: 1.0362 - val_accuracy: 0.6728\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.6111 - accuracy: 0.8030 - val_loss: 0.9895 - val_accuracy: 0.6793\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.5784 - accuracy: 0.8160 - val_loss: 1.0113 - val_accuracy: 0.6702\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.5643 - accuracy: 0.8200 - val_loss: 1.0045 - val_accuracy: 0.6792\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.5498 - accuracy: 0.8243 - val_loss: 1.0066 - val_accuracy: 0.6774\n",
      "\n",
      "Round = 18, total number of trainable parameters = 82899\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 19\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.9588, Accuracy: 31.6920, Test Loss: 1.7999, Test Accuracy: 41.750000\n",
      "Total number of trainable parameters = 82871\n",
      "\n",
      "Epoch 2, Loss: 1.7063, Accuracy: 46.5900, Test Loss: 1.6356, Test Accuracy: 48.320000\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 3, Loss: 1.5645, Accuracy: 52.6760, Test Loss: 1.5291, Test Accuracy: 53.420002\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 4, Loss: 1.4536, Accuracy: 56.6660, Test Loss: 1.4419, Test Accuracy: 56.279999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 5, Loss: 1.3573, Accuracy: 59.7760, Test Loss: 1.3624, Test Accuracy: 58.439999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 6, Loss: 1.2676, Accuracy: 62.2940, Test Loss: 1.2981, Test Accuracy: 60.160000\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 7, Loss: 1.1850, Accuracy: 64.8940, Test Loss: 1.2363, Test Accuracy: 61.659996\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 8, Loss: 1.1114, Accuracy: 66.8780, Test Loss: 1.1856, Test Accuracy: 62.739998\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 9, Loss: 1.0484, Accuracy: 68.3880, Test Loss: 1.1490, Test Accuracy: 63.779999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 10, Loss: 0.9955, Accuracy: 69.5920, Test Loss: 1.1139, Test Accuracy: 64.139999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 11, Loss: 0.9470, Accuracy: 70.7840, Test Loss: 1.0990, Test Accuracy: 64.910004\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 12, Loss: 0.9061, Accuracy: 71.7660, Test Loss: 1.0704, Test Accuracy: 65.139999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 13, Loss: 0.8691, Accuracy: 72.5880, Test Loss: 1.0531, Test Accuracy: 65.410004\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 14, Loss: 0.8355, Accuracy: 73.6600, Test Loss: 1.0367, Test Accuracy: 66.259995\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 15, Loss: 0.8049, Accuracy: 74.5260, Test Loss: 1.0264, Test Accuracy: 66.479996\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 16, Loss: 0.7787, Accuracy: 75.1520, Test Loss: 1.0247, Test Accuracy: 66.619995\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 17, Loss: 0.7523, Accuracy: 76.0240, Test Loss: 1.0283, Test Accuracy: 66.689995\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 18, Loss: 0.7297, Accuracy: 76.6080, Test Loss: 1.0200, Test Accuracy: 66.930000\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 19, Loss: 0.7091, Accuracy: 77.2800, Test Loss: 1.0168, Test Accuracy: 67.110001\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 20, Loss: 0.6911, Accuracy: 77.8100, Test Loss: 1.0130, Test Accuracy: 67.059998\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 21, Loss: 0.6725, Accuracy: 78.4980, Test Loss: 1.0127, Test Accuracy: 67.079994\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 22, Loss: 0.6553, Accuracy: 78.9120, Test Loss: 1.0083, Test Accuracy: 67.089996\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 23, Loss: 0.6391, Accuracy: 79.5840, Test Loss: 1.0157, Test Accuracy: 67.049995\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 24, Loss: 0.6233, Accuracy: 80.0700, Test Loss: 1.0277, Test Accuracy: 67.189995\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 25, Loss: 0.6098, Accuracy: 80.5240, Test Loss: 1.0067, Test Accuracy: 67.309998\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 26, Loss: 0.5966, Accuracy: 80.9460, Test Loss: 1.0046, Test Accuracy: 67.739998\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 27, Loss: 0.5833, Accuracy: 81.2280, Test Loss: 1.0273, Test Accuracy: 67.470001\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 28, Loss: 0.5702, Accuracy: 81.6300, Test Loss: 1.0211, Test Accuracy: 67.330002\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "Epoch 29, Loss: 0.5579, Accuracy: 82.0660, Test Loss: 1.0202, Test Accuracy: 67.529999\n",
      "Total number of trainable parameters = 82873\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.5453 - accuracy: 0.8254 - val_loss: 1.0372 - val_accuracy: 0.6740\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.5819 - accuracy: 0.8121 - val_loss: 1.0185 - val_accuracy: 0.6682\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.5536 - accuracy: 0.8224 - val_loss: 1.0280 - val_accuracy: 0.6739\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.5387 - accuracy: 0.8284 - val_loss: 1.0429 - val_accuracy: 0.6752\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 0.5260 - accuracy: 0.8306 - val_loss: 1.0403 - val_accuracy: 0.6746\n",
      "\n",
      "Round = 19, total number of trainable parameters = 66949\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 20\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 1.9842, Accuracy: 30.1120, Test Loss: 1.8357, Test Accuracy: 39.829998\n",
      "Total number of trainable parameters = 66926\n",
      "\n",
      "Epoch 2, Loss: 1.7400, Accuracy: 45.0040, Test Loss: 1.6758, Test Accuracy: 48.829998\n",
      "Total number of trainable parameters = 66926\n",
      "\n",
      "Epoch 3, Loss: 1.5958, Accuracy: 51.2280, Test Loss: 1.5581, Test Accuracy: 53.039997\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 4, Loss: 1.4798, Accuracy: 55.5500, Test Loss: 1.4593, Test Accuracy: 55.029999\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 5, Loss: 1.3772, Accuracy: 59.1060, Test Loss: 1.3809, Test Accuracy: 57.410004\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 6, Loss: 1.2862, Accuracy: 61.7500, Test Loss: 1.3107, Test Accuracy: 59.590000\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 7, Loss: 1.2054, Accuracy: 63.9700, Test Loss: 1.2651, Test Accuracy: 60.849998\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 8, Loss: 1.1352, Accuracy: 65.8320, Test Loss: 1.2042, Test Accuracy: 62.620003\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 9, Loss: 1.0739, Accuracy: 67.3040, Test Loss: 1.1691, Test Accuracy: 63.650002\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 10, Loss: 1.0195, Accuracy: 68.7560, Test Loss: 1.1335, Test Accuracy: 64.240005\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 11, Loss: 0.9711, Accuracy: 69.9600, Test Loss: 1.1088, Test Accuracy: 64.440002\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 12, Loss: 0.9295, Accuracy: 70.9820, Test Loss: 1.0956, Test Accuracy: 64.090004\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 13, Loss: 0.8912, Accuracy: 72.0180, Test Loss: 1.0645, Test Accuracy: 65.690002\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 14, Loss: 0.8563, Accuracy: 73.1140, Test Loss: 1.0537, Test Accuracy: 66.019997\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 15, Loss: 0.8254, Accuracy: 73.9460, Test Loss: 1.0413, Test Accuracy: 66.329994\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 16, Loss: 0.7969, Accuracy: 74.7380, Test Loss: 1.0365, Test Accuracy: 66.659996\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 17, Loss: 0.7724, Accuracy: 75.3700, Test Loss: 1.0249, Test Accuracy: 67.059998\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 18, Loss: 0.7481, Accuracy: 76.0700, Test Loss: 1.0258, Test Accuracy: 67.129997\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 19, Loss: 0.7276, Accuracy: 76.7340, Test Loss: 1.0142, Test Accuracy: 67.059998\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 20, Loss: 0.7069, Accuracy: 77.2460, Test Loss: 1.0315, Test Accuracy: 66.449997\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 21, Loss: 0.6894, Accuracy: 77.8960, Test Loss: 1.0115, Test Accuracy: 67.470001\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 22, Loss: 0.6722, Accuracy: 78.3400, Test Loss: 1.0286, Test Accuracy: 67.040001\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 23, Loss: 0.6552, Accuracy: 79.0700, Test Loss: 1.0173, Test Accuracy: 67.439995\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "Epoch 24, Loss: 0.6401, Accuracy: 79.3460, Test Loss: 1.0162, Test Accuracy: 67.580002\n",
      "Total number of trainable parameters = 66927\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.6266 - accuracy: 0.7978 - val_loss: 1.0255 - val_accuracy: 0.6710\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.6547 - accuracy: 0.7874 - val_loss: 1.0051 - val_accuracy: 0.6728\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6326 - accuracy: 0.7970 - val_loss: 1.0161 - val_accuracy: 0.6679\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6193 - accuracy: 0.8004 - val_loss: 1.0216 - val_accuracy: 0.6776\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6051 - accuracy: 0.8038 - val_loss: 1.0288 - val_accuracy: 0.6760\n",
      "\n",
      "Round = 20, total number of trainable parameters = 54131\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 21\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 2.0078, Accuracy: 29.2280, Test Loss: 1.8658, Test Accuracy: 38.889999\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 2, Loss: 1.7668, Accuracy: 43.7600, Test Loss: 1.6895, Test Accuracy: 46.520000\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 3, Loss: 1.6166, Accuracy: 50.3900, Test Loss: 1.5713, Test Accuracy: 49.910000\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 4, Loss: 1.4998, Accuracy: 54.5280, Test Loss: 1.4800, Test Accuracy: 54.210003\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 5, Loss: 1.3998, Accuracy: 57.5500, Test Loss: 1.3959, Test Accuracy: 56.459999\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 6, Loss: 1.3136, Accuracy: 60.3200, Test Loss: 1.3306, Test Accuracy: 58.250000\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 7, Loss: 1.2364, Accuracy: 62.5880, Test Loss: 1.2767, Test Accuracy: 60.130001\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 8, Loss: 1.1677, Accuracy: 64.6460, Test Loss: 1.2405, Test Accuracy: 60.630001\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 9, Loss: 1.1069, Accuracy: 65.9560, Test Loss: 1.1901, Test Accuracy: 62.589996\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 10, Loss: 1.0546, Accuracy: 67.4440, Test Loss: 1.1555, Test Accuracy: 63.120003\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 11, Loss: 1.0055, Accuracy: 68.5920, Test Loss: 1.1334, Test Accuracy: 63.830002\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 12, Loss: 0.9638, Accuracy: 69.7300, Test Loss: 1.1088, Test Accuracy: 64.240005\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 13, Loss: 0.9269, Accuracy: 70.5900, Test Loss: 1.0897, Test Accuracy: 65.070000\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 14, Loss: 0.8928, Accuracy: 71.5400, Test Loss: 1.0805, Test Accuracy: 65.080002\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 15, Loss: 0.8607, Accuracy: 72.5460, Test Loss: 1.0603, Test Accuracy: 65.500000\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 16, Loss: 0.8326, Accuracy: 73.4300, Test Loss: 1.0430, Test Accuracy: 66.059998\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 17, Loss: 0.8082, Accuracy: 74.0340, Test Loss: 1.0436, Test Accuracy: 65.510002\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 18, Loss: 0.7842, Accuracy: 74.7760, Test Loss: 1.0389, Test Accuracy: 66.439995\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 19, Loss: 0.7634, Accuracy: 75.3260, Test Loss: 1.0220, Test Accuracy: 66.699997\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 20, Loss: 0.7432, Accuracy: 75.9960, Test Loss: 1.0220, Test Accuracy: 66.659996\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 21, Loss: 0.7270, Accuracy: 76.5140, Test Loss: 1.0175, Test Accuracy: 66.849998\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 22, Loss: 0.7091, Accuracy: 76.9780, Test Loss: 1.0261, Test Accuracy: 66.389999\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 23, Loss: 0.6941, Accuracy: 77.4840, Test Loss: 1.0135, Test Accuracy: 66.599998\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 24, Loss: 0.6803, Accuracy: 77.9420, Test Loss: 1.0166, Test Accuracy: 66.989998\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 25, Loss: 0.6667, Accuracy: 78.4400, Test Loss: 1.0291, Test Accuracy: 67.259995\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "Epoch 26, Loss: 0.6536, Accuracy: 78.7080, Test Loss: 1.0224, Test Accuracy: 67.209999\n",
      "Total number of trainable parameters = 54115\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.6417 - accuracy: 0.7917 - val_loss: 1.0466 - val_accuracy: 0.6715\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.7056 - accuracy: 0.7687 - val_loss: 1.0205 - val_accuracy: 0.6681\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.6756 - accuracy: 0.7791 - val_loss: 1.0250 - val_accuracy: 0.6685\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 79s 2ms/sample - loss: 0.6587 - accuracy: 0.7840 - val_loss: 1.0235 - val_accuracy: 0.6674\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6448 - accuracy: 0.7885 - val_loss: 1.0337 - val_accuracy: 0.6626\n",
      "\n",
      "Round = 21, total number of trainable parameters = 43800\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 22\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 2.0585, Accuracy: 25.6220, Test Loss: 1.9279, Test Accuracy: 32.520000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 2, Loss: 1.8382, Accuracy: 38.6260, Test Loss: 1.7673, Test Accuracy: 40.720001\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 3, Loss: 1.6962, Accuracy: 45.2100, Test Loss: 1.6542, Test Accuracy: 46.299999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 4, Loss: 1.5838, Accuracy: 49.5940, Test Loss: 1.5610, Test Accuracy: 48.400002\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 5, Loss: 1.4898, Accuracy: 53.2240, Test Loss: 1.4804, Test Accuracy: 53.240002\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 6, Loss: 1.4058, Accuracy: 56.4120, Test Loss: 1.4074, Test Accuracy: 55.299995\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 7, Loss: 1.3310, Accuracy: 58.7780, Test Loss: 1.3504, Test Accuracy: 56.739998\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 8, Loss: 1.2624, Accuracy: 60.9020, Test Loss: 1.2977, Test Accuracy: 58.209999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 9, Loss: 1.2013, Accuracy: 62.5280, Test Loss: 1.2530, Test Accuracy: 59.660000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 10, Loss: 1.1467, Accuracy: 63.9360, Test Loss: 1.2142, Test Accuracy: 60.829998\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 11, Loss: 1.0994, Accuracy: 65.2520, Test Loss: 1.1874, Test Accuracy: 61.299999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 12, Loss: 1.0548, Accuracy: 66.5720, Test Loss: 1.1669, Test Accuracy: 62.430000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 13, Loss: 1.0164, Accuracy: 67.5340, Test Loss: 1.1383, Test Accuracy: 62.720001\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 14, Loss: 0.9808, Accuracy: 68.4820, Test Loss: 1.1141, Test Accuracy: 63.260002\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 15, Loss: 0.9492, Accuracy: 69.4680, Test Loss: 1.0999, Test Accuracy: 64.000000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 16, Loss: 0.9214, Accuracy: 70.2860, Test Loss: 1.0891, Test Accuracy: 63.980000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 17, Loss: 0.8938, Accuracy: 70.9500, Test Loss: 1.0764, Test Accuracy: 64.529999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 18, Loss: 0.8722, Accuracy: 71.6280, Test Loss: 1.0706, Test Accuracy: 64.950005\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 19, Loss: 0.8488, Accuracy: 72.3560, Test Loss: 1.0570, Test Accuracy: 65.029999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 20, Loss: 0.8296, Accuracy: 72.9380, Test Loss: 1.0494, Test Accuracy: 65.540001\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 21, Loss: 0.8099, Accuracy: 73.4780, Test Loss: 1.0450, Test Accuracy: 65.400002\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 22, Loss: 0.7930, Accuracy: 74.0680, Test Loss: 1.0401, Test Accuracy: 65.930000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 23, Loss: 0.7771, Accuracy: 74.6400, Test Loss: 1.0388, Test Accuracy: 65.849998\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 24, Loss: 0.7622, Accuracy: 74.9880, Test Loss: 1.0393, Test Accuracy: 65.830002\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 25, Loss: 0.7493, Accuracy: 75.2720, Test Loss: 1.0360, Test Accuracy: 66.180000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 26, Loss: 0.7372, Accuracy: 75.7420, Test Loss: 1.0354, Test Accuracy: 66.469994\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 27, Loss: 0.7234, Accuracy: 76.2000, Test Loss: 1.0370, Test Accuracy: 66.430000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 28, Loss: 0.7127, Accuracy: 76.4020, Test Loss: 1.0395, Test Accuracy: 66.529999\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 29, Loss: 0.7017, Accuracy: 76.9140, Test Loss: 1.0314, Test Accuracy: 66.549995\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 30, Loss: 0.6912, Accuracy: 77.3340, Test Loss: 1.0335, Test Accuracy: 67.009995\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 31, Loss: 0.6822, Accuracy: 77.5540, Test Loss: 1.0433, Test Accuracy: 66.250000\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "Epoch 32, Loss: 0.6733, Accuracy: 77.7820, Test Loss: 1.0390, Test Accuracy: 66.439995\n",
      "Total number of trainable parameters = 43778\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.6635 - accuracy: 0.7800 - val_loss: 1.0423 - val_accuracy: 0.6661\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.8546 - accuracy: 0.7073 - val_loss: 1.1652 - val_accuracy: 0.5960\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.8382 - accuracy: 0.6969 - val_loss: 1.1440 - val_accuracy: 0.5999\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.8063 - accuracy: 0.7384 - val_loss: 1.1326 - val_accuracy: 0.6368\n",
      "\n",
      "Round = 22, total number of trainable parameters = 35512\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 23\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 2.0874, Accuracy: 25.9780, Test Loss: 1.9662, Test Accuracy: 33.469997\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 2, Loss: 1.8810, Accuracy: 37.8280, Test Loss: 1.8219, Test Accuracy: 38.959999\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 3, Loss: 1.7493, Accuracy: 43.7100, Test Loss: 1.7074, Test Accuracy: 45.000000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 4, Loss: 1.6428, Accuracy: 47.7260, Test Loss: 1.6185, Test Accuracy: 48.150002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 5, Loss: 1.5509, Accuracy: 51.0320, Test Loss: 1.5433, Test Accuracy: 50.570000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 6, Loss: 1.4699, Accuracy: 54.1600, Test Loss: 1.4722, Test Accuracy: 53.480000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 7, Loss: 1.3976, Accuracy: 56.8600, Test Loss: 1.4174, Test Accuracy: 54.730000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 8, Loss: 1.3324, Accuracy: 58.9660, Test Loss: 1.3661, Test Accuracy: 56.180000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 9, Loss: 1.2755, Accuracy: 60.7140, Test Loss: 1.3286, Test Accuracy: 57.669998\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 10, Loss: 1.2255, Accuracy: 61.9240, Test Loss: 1.2892, Test Accuracy: 58.960003\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 11, Loss: 1.1799, Accuracy: 63.2040, Test Loss: 1.2623, Test Accuracy: 59.420002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 12, Loss: 1.1400, Accuracy: 64.1780, Test Loss: 1.2459, Test Accuracy: 60.350002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 13, Loss: 1.1025, Accuracy: 65.3980, Test Loss: 1.2176, Test Accuracy: 61.070000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 14, Loss: 1.0701, Accuracy: 66.1600, Test Loss: 1.2041, Test Accuracy: 61.139999\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 15, Loss: 1.0413, Accuracy: 66.9420, Test Loss: 1.1953, Test Accuracy: 61.180000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 16, Loss: 1.0128, Accuracy: 67.7960, Test Loss: 1.1699, Test Accuracy: 62.690002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 17, Loss: 0.9888, Accuracy: 68.6300, Test Loss: 1.1531, Test Accuracy: 62.910004\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 18, Loss: 0.9652, Accuracy: 69.3460, Test Loss: 1.1469, Test Accuracy: 63.090004\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 19, Loss: 0.9448, Accuracy: 69.8480, Test Loss: 1.1312, Test Accuracy: 63.169998\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 20, Loss: 0.9249, Accuracy: 70.4040, Test Loss: 1.1283, Test Accuracy: 63.580002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 21, Loss: 0.9066, Accuracy: 71.0160, Test Loss: 1.1192, Test Accuracy: 63.700001\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 22, Loss: 0.8910, Accuracy: 71.4760, Test Loss: 1.1183, Test Accuracy: 63.970001\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 23, Loss: 0.8748, Accuracy: 71.8340, Test Loss: 1.1103, Test Accuracy: 63.650002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 24, Loss: 0.8603, Accuracy: 72.4080, Test Loss: 1.1062, Test Accuracy: 63.880001\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 25, Loss: 0.8467, Accuracy: 72.7900, Test Loss: 1.0990, Test Accuracy: 64.440002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 26, Loss: 0.8348, Accuracy: 73.0420, Test Loss: 1.0987, Test Accuracy: 64.300003\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 27, Loss: 0.8229, Accuracy: 73.5060, Test Loss: 1.0984, Test Accuracy: 64.660004\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 28, Loss: 0.8118, Accuracy: 73.7860, Test Loss: 1.0927, Test Accuracy: 64.400002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 29, Loss: 0.8017, Accuracy: 74.1200, Test Loss: 1.0929, Test Accuracy: 64.700005\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 30, Loss: 0.7909, Accuracy: 74.3700, Test Loss: 1.0974, Test Accuracy: 64.910004\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 31, Loss: 0.7821, Accuracy: 74.5680, Test Loss: 1.0903, Test Accuracy: 64.830002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 32, Loss: 0.7734, Accuracy: 74.8960, Test Loss: 1.0898, Test Accuracy: 65.100006\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 33, Loss: 0.7648, Accuracy: 75.2020, Test Loss: 1.0931, Test Accuracy: 65.060005\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 34, Loss: 0.7571, Accuracy: 75.3940, Test Loss: 1.0897, Test Accuracy: 65.080002\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 35, Loss: 0.7478, Accuracy: 75.6020, Test Loss: 1.0914, Test Accuracy: 65.180000\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 36, Loss: 0.7410, Accuracy: 76.0400, Test Loss: 1.0927, Test Accuracy: 65.349998\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "Epoch 37, Loss: 0.7334, Accuracy: 76.0660, Test Loss: 1.0922, Test Accuracy: 65.380005\n",
      "Total number of trainable parameters = 35497\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.7261 - accuracy: 0.7635 - val_loss: 1.0903 - val_accuracy: 0.6535\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 0.9540 - accuracy: 0.6928 - val_loss: 1.2788 - val_accuracy: 0.5899\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.9495 - accuracy: 0.6856 - val_loss: 1.2598 - val_accuracy: 0.5955\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 78s 2ms/sample - loss: 0.9188 - accuracy: 0.6903 - val_loss: 1.2410 - val_accuracy: 0.5944\n",
      "\n",
      "Round = 23, total number of trainable parameters = 28808\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 24\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 2.1106, Accuracy: 25.6100, Test Loss: 1.9993, Test Accuracy: 33.289997\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 2, Loss: 1.9260, Accuracy: 36.4620, Test Loss: 1.8739, Test Accuracy: 37.810001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 3, Loss: 1.8115, Accuracy: 41.6860, Test Loss: 1.7835, Test Accuracy: 41.940002\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 4, Loss: 1.7198, Accuracy: 44.7160, Test Loss: 1.6978, Test Accuracy: 45.020000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 5, Loss: 1.6375, Accuracy: 47.6080, Test Loss: 1.6262, Test Accuracy: 47.060001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 6, Loss: 1.5646, Accuracy: 49.9840, Test Loss: 1.5670, Test Accuracy: 47.830002\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 7, Loss: 1.4996, Accuracy: 51.1500, Test Loss: 1.5109, Test Accuracy: 49.000000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 8, Loss: 1.4418, Accuracy: 52.5960, Test Loss: 1.4705, Test Accuracy: 50.000000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 9, Loss: 1.3918, Accuracy: 53.7760, Test Loss: 1.4294, Test Accuracy: 52.530003\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 10, Loss: 1.3481, Accuracy: 55.4640, Test Loss: 1.3995, Test Accuracy: 52.969997\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 11, Loss: 1.3082, Accuracy: 57.0020, Test Loss: 1.3745, Test Accuracy: 53.660000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 12, Loss: 1.2730, Accuracy: 57.4740, Test Loss: 1.3438, Test Accuracy: 54.910000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 13, Loss: 1.2403, Accuracy: 58.1960, Test Loss: 1.3255, Test Accuracy: 55.470001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 14, Loss: 1.2120, Accuracy: 58.5560, Test Loss: 1.3108, Test Accuracy: 53.860004\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 15, Loss: 1.1855, Accuracy: 58.8660, Test Loss: 1.3043, Test Accuracy: 54.079998\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 16, Loss: 1.1612, Accuracy: 59.9680, Test Loss: 1.2923, Test Accuracy: 54.389999\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 17, Loss: 1.1385, Accuracy: 60.1440, Test Loss: 1.2705, Test Accuracy: 54.759998\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 18, Loss: 1.1192, Accuracy: 61.4020, Test Loss: 1.2516, Test Accuracy: 54.970001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 19, Loss: 1.0997, Accuracy: 61.4300, Test Loss: 1.2531, Test Accuracy: 54.910000\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 20, Loss: 1.0817, Accuracy: 61.2940, Test Loss: 1.2470, Test Accuracy: 55.459999\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 21, Loss: 1.0661, Accuracy: 61.8720, Test Loss: 1.2592, Test Accuracy: 55.099998\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 22, Loss: 1.0503, Accuracy: 62.8120, Test Loss: 1.2303, Test Accuracy: 55.769997\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 23, Loss: 1.0358, Accuracy: 63.6820, Test Loss: 1.2259, Test Accuracy: 56.010002\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 24, Loss: 1.0226, Accuracy: 63.5720, Test Loss: 1.2192, Test Accuracy: 56.279999\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 25, Loss: 1.0097, Accuracy: 63.3540, Test Loss: 1.2184, Test Accuracy: 56.230003\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 26, Loss: 0.9984, Accuracy: 63.7680, Test Loss: 1.2261, Test Accuracy: 56.290001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 27, Loss: 0.9862, Accuracy: 64.7580, Test Loss: 1.2123, Test Accuracy: 56.879997\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 28, Loss: 0.9759, Accuracy: 64.3680, Test Loss: 1.2080, Test Accuracy: 56.489998\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 29, Loss: 0.9656, Accuracy: 64.6560, Test Loss: 1.2159, Test Accuracy: 56.629997\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 30, Loss: 0.9559, Accuracy: 65.0420, Test Loss: 1.2046, Test Accuracy: 56.970001\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 31, Loss: 0.9472, Accuracy: 65.1440, Test Loss: 1.2096, Test Accuracy: 56.660004\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 32, Loss: 0.9381, Accuracy: 65.4700, Test Loss: 1.2153, Test Accuracy: 56.650002\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "Epoch 33, Loss: 0.9297, Accuracy: 65.9720, Test Loss: 1.2242, Test Accuracy: 56.730003\n",
      "Total number of trainable parameters = 28797\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 0.9226 - accuracy: 0.6602 - val_loss: 1.2015 - val_accuracy: 0.5696\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 1.4091 - accuracy: 0.5468 - val_loss: 1.6711 - val_accuracy: 0.4731\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 1.4099 - accuracy: 0.5497 - val_loss: 1.5896 - val_accuracy: 0.4876\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 77s 2ms/sample - loss: 1.3294 - accuracy: 0.5614 - val_loss: 1.5178 - val_accuracy: 0.4953\n",
      "\n",
      "Round = 24, total number of trainable parameters = 23426\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Iterative pruning round: 25\n",
      "\n",
      "\n",
      "Epoch 1, Loss: 2.1469, Accuracy: 24.1080, Test Loss: 2.0482, Test Accuracy: 31.459999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 2, Loss: 1.9844, Accuracy: 34.2040, Test Loss: 1.9382, Test Accuracy: 36.329998\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 3, Loss: 1.8876, Accuracy: 38.5540, Test Loss: 1.8545, Test Accuracy: 39.090000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 4, Loss: 1.8099, Accuracy: 41.4680, Test Loss: 1.7913, Test Accuracy: 40.810001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 5, Loss: 1.7425, Accuracy: 44.1720, Test Loss: 1.7324, Test Accuracy: 44.049999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 6, Loss: 1.6803, Accuracy: 46.2020, Test Loss: 1.6734, Test Accuracy: 45.230000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 7, Loss: 1.6224, Accuracy: 47.5800, Test Loss: 1.6267, Test Accuracy: 46.380001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 8, Loss: 1.5704, Accuracy: 49.2760, Test Loss: 1.5789, Test Accuracy: 48.139999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 9, Loss: 1.5225, Accuracy: 50.4560, Test Loss: 1.5408, Test Accuracy: 48.849998\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 10, Loss: 1.4801, Accuracy: 51.5700, Test Loss: 1.5079, Test Accuracy: 48.859997\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 11, Loss: 1.4424, Accuracy: 51.5500, Test Loss: 1.4801, Test Accuracy: 49.779999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 12, Loss: 1.4080, Accuracy: 52.7120, Test Loss: 1.4580, Test Accuracy: 49.480000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 13, Loss: 1.3775, Accuracy: 53.2920, Test Loss: 1.4343, Test Accuracy: 50.059998\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 14, Loss: 1.3504, Accuracy: 53.2780, Test Loss: 1.4162, Test Accuracy: 49.829998\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 15, Loss: 1.3255, Accuracy: 54.4500, Test Loss: 1.4015, Test Accuracy: 50.430000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 16, Loss: 1.3026, Accuracy: 54.9780, Test Loss: 1.3877, Test Accuracy: 51.290001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 17, Loss: 1.2825, Accuracy: 54.5700, Test Loss: 1.3782, Test Accuracy: 51.130001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 18, Loss: 1.2633, Accuracy: 55.0140, Test Loss: 1.3633, Test Accuracy: 51.209999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 19, Loss: 1.2472, Accuracy: 55.7400, Test Loss: 1.3545, Test Accuracy: 51.310001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 20, Loss: 1.2315, Accuracy: 56.1600, Test Loss: 1.3755, Test Accuracy: 51.340000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 21, Loss: 1.2168, Accuracy: 57.0980, Test Loss: 1.3424, Test Accuracy: 51.660000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 22, Loss: 1.2034, Accuracy: 57.6440, Test Loss: 1.3372, Test Accuracy: 51.799999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 23, Loss: 1.1908, Accuracy: 56.5180, Test Loss: 1.3343, Test Accuracy: 51.920002\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 24, Loss: 1.1799, Accuracy: 57.6120, Test Loss: 1.3306, Test Accuracy: 52.039997\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 25, Loss: 1.1684, Accuracy: 57.2560, Test Loss: 1.3400, Test Accuracy: 51.889999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 26, Loss: 1.1582, Accuracy: 57.8480, Test Loss: 1.3378, Test Accuracy: 51.750000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 27, Loss: 1.1495, Accuracy: 58.3760, Test Loss: 1.3253, Test Accuracy: 54.529999\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 28, Loss: 1.1406, Accuracy: 58.3700, Test Loss: 1.3178, Test Accuracy: 53.060001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 29, Loss: 1.1321, Accuracy: 58.6220, Test Loss: 1.3136, Test Accuracy: 52.039997\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 30, Loss: 1.1232, Accuracy: 59.2500, Test Loss: 1.3150, Test Accuracy: 54.750000\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 31, Loss: 1.1156, Accuracy: 59.3020, Test Loss: 1.3136, Test Accuracy: 52.640003\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 32, Loss: 1.1086, Accuracy: 59.5540, Test Loss: 1.3130, Test Accuracy: 52.490002\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 33, Loss: 1.1016, Accuracy: 59.3620, Test Loss: 1.3250, Test Accuracy: 52.490002\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 34, Loss: 1.0949, Accuracy: 59.2660, Test Loss: 1.3205, Test Accuracy: 52.399998\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "Epoch 35, Loss: 1.0880, Accuracy: 59.6400, Test Loss: 1.3173, Test Accuracy: 52.700001\n",
      "Total number of trainable parameters = 23405\n",
      "\n",
      "\n",
      "'EarlyStopping' called!\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 1.0821 - accuracy: 0.5922 - val_loss: 1.3079 - val_accuracy: 0.5240\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 1.9236 - accuracy: 0.4560 - val_loss: 2.2016 - val_accuracy: 0.3873\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 76s 2ms/sample - loss: 1.9686 - accuracy: 0.4450 - val_loss: 2.0662 - val_accuracy: 0.4046\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 75s 2ms/sample - loss: 1.8430 - accuracy: 0.4560 - val_loss: 1.9622 - val_accuracy: 0.4197\n",
      "\n",
      "Round = 25, total number of trainable parameters = 19090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, num_pruning_rounds + 1):\n",
    "    \n",
    "    print(\"\\n\\n\\nIterative pruning round: {0}\\n\\n\".format(i))\n",
    "    \n",
    "    # Define 'train_one_step()' and 'test_step()' functions here-\n",
    "    @tf.function\n",
    "    def train_one_step(model, mask_model, optimizer, x, y):\n",
    "        '''\n",
    "        Function to compute one step of gradient descent optimization\n",
    "        '''\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Make predictions using defined model-\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Compute loss-\n",
    "            loss = loss_fn(y, y_pred)\n",
    "        \n",
    "        # Compute gradients wrt defined loss and weights and biases-\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "        # type(grads)\n",
    "        # list\n",
    "    \n",
    "        # List to hold element-wise multiplication between-\n",
    "        # computed gradient and masks-\n",
    "        grad_mask_mul = []\n",
    "    \n",
    "        # Perform element-wise multiplication between computed gradients and masks-\n",
    "        for grad_layer, mask in zip(grads, mask_model.trainable_weights):\n",
    "            grad_mask_mul.append(tf.math.multiply(grad_layer, mask))\n",
    "    \n",
    "        # Apply computed gradients to model's weights and biases-\n",
    "        optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\n",
    "\n",
    "        # Compute accuracy-\n",
    "        train_loss(loss)\n",
    "        train_accuracy(y, y_pred)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(model, optimizer, data, labels):\n",
    "        \"\"\"\n",
    "        Function to test model performance\n",
    "        on testing dataset\n",
    "        \"\"\"\n",
    "    \n",
    "        predictions = model(data)\n",
    "        t_loss = loss_fn(labels, predictions)\n",
    "\n",
    "        test_loss(t_loss)\n",
    "        test_accuracy(labels, predictions)\n",
    "\n",
    "        return None\n",
    "\n",
    "\n",
    "    # Instantiate a model\n",
    "    model_gt = pruned_nn(pruning_params_unpruned, pruning_params_unpruned)\n",
    "    \n",
    "    # Load winning ticket (from above)-\n",
    "    model_gt.load_weights(\"Conv_2_CIFAR_Winning_Ticket.h5\")\n",
    "    \n",
    "    # Strip model of pruning parameters-\n",
    "    model_gt_stripped = sparsity.strip_pruning(model_gt)\n",
    "    \n",
    "    \n",
    "    # Train model using 'GradientTape'-\n",
    "    \n",
    "    # Initialize parameters for Early Stopping manual implementation-\n",
    "    best_val_loss = 100\n",
    "    loc_patience = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "    \n",
    "        if loc_patience >= patience:\n",
    "            print(\"\\n'EarlyStopping' called!\\n\")\n",
    "            break\n",
    "        \n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        # Initialize 'grad_mask_mul' list-\n",
    "        grad_mask_mul = []\n",
    "    \n",
    "        # Initialize all values to one-\n",
    "        for wts in mask_model_stripped.trainable_weights:\n",
    "            grad_mask_mul.append(wts.assign(tf.ones_like(input = wts,dtype = tf.float32)))\n",
    "    \n",
    "        # Convert from Python list to tf.Tensor-\n",
    "        grad_mask_mul = tf.convert_to_tensor(grad_mask_mul, dtype=tf.float32)\n",
    "    \n",
    "        print(\"type(grad_mask_mul): {0}\".format(type(grad_mask_mul)))\n",
    "        '''\n",
    "    \n",
    "        for x, y in train_dataset:\n",
    "            # train_one_step(model_gt_stripped, mask_model, optimizer, x, y, grad_mask_mul)\n",
    "            train_one_step(model_gt_stripped, mask_model_stripped, optimizer, x, y)\n",
    "\n",
    "\n",
    "        for x_t, y_t in test_dataset:\n",
    "            # test_step(x_t, y_t)\n",
    "            test_step(model_gt_stripped, optimizer, x_t, y_t)\n",
    "\n",
    "        template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, Test Loss: {3:.4f}, Test Accuracy: {4:4f}'\n",
    "    \n",
    "        # 'i' is the index for number of pruning rounds-\n",
    "        history_main[i]['accuracy'][epoch] = train_accuracy.result() * 100\n",
    "        history_main[i]['loss'][epoch] = train_loss.result()\n",
    "        history_main[i]['val_loss'][epoch] = test_loss.result()\n",
    "        history_main[i]['val_accuracy'][epoch] = test_accuracy.result() * 100\n",
    "        \n",
    "        print(template.format(epoch + 1, \n",
    "                              train_loss.result(), train_accuracy.result()*100,\n",
    "                              test_loss.result(), test_accuracy.result()*100))\n",
    "    \n",
    "        # Count number of non-zero parameters in each layer and in total-\n",
    "        # print(\"layer-wise manner model, number of nonzero parameters in each layer are: \\n\")\n",
    "\n",
    "        model_sum_params = 0\n",
    "    \n",
    "        for layer in model_gt_stripped.trainable_weights:\n",
    "            # print(tf.math.count_nonzero(layer, axis = None).numpy())\n",
    "            model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "    \n",
    "        print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\n",
    "\n",
    "    \n",
    "        # Code for manual Early Stopping:\n",
    "        if np.abs(test_loss.result() < best_val_loss) >= minimum_delta:\n",
    "            # update 'best_val_loss' variable to lowest loss encountered so far-\n",
    "            best_val_loss = test_loss.result()\n",
    "        \n",
    "            # reset 'loc_patience' variable-\n",
    "            loc_patience = 0\n",
    "        \n",
    "        else:  # there is no improvement in monitored metric 'val_loss'\n",
    "            loc_patience += 1  # number of epochs without any improvement\n",
    "\n",
    "    \n",
    "    # Resize numpy arrays according to the epoch when 'EarlyStopping' was called-\n",
    "    for metrics in history_main[i].keys():\n",
    "        history_main[i][metrics] = np.resize(history_main[i][metrics], new_shape = epoch)\n",
    "        # history[metrics] = np.resize(history[metrics], new_shape=epoch)\n",
    "     \n",
    "    \n",
    "    # Save trained model weights-\n",
    "    model_gt.save_weights(\"Conv_2_CIFAR_Trained_Weights.h5\", overwrite=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Prune trained model:\n",
    "    \n",
    "    # print(\"\\n% of weights to be pruned in round = {0} is: {1:.4f}\\n\".format(i, wts_np[i - 1]))\n",
    "    \n",
    "    # Specify the parameters to be used for layer-wise pruning, Conv layer-\n",
    "    pruning_params_conv = {\n",
    "        'pruning_schedule': sparsity.ConstantSparsity(\n",
    "            target_sparsity=conv1_pruning[i - 1], begin_step = 1000,\n",
    "            end_step = end_step, frequency=100\n",
    "        )\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Specify the parameters to be used for layer-wise pruning, Fully-Connected layer pruning-\n",
    "    pruning_params_fc = {\n",
    "        'pruning_schedule': sparsity.ConstantSparsity(\n",
    "            target_sparsity=dense1_pruning[i - 1], begin_step = 1000,\n",
    "            end_step = end_step, frequency=100\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Instantiate a Nueal Network model to be pruned using parameters from above-\n",
    "    pruned_model = pruned_nn(pruning_params_conv, pruning_params_fc)\n",
    "    \n",
    "    # Load weights from original trained and unpruned model-\n",
    "    pruned_model.load_weights(\"Conv_2_CIFAR_Trained_Weights.h5\")\n",
    "    \n",
    "    # Train pruned NN-\n",
    "    history_pruned = pruned_model.fit(\n",
    "        x = X_train, y = y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        verbose = 1,\n",
    "        callbacks = callback,\n",
    "        validation_data = (X_test, y_test),\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    # Strip the pruning wrappers from pruned model-\n",
    "    pruned_model_stripped = sparsity.strip_pruning(pruned_model)\n",
    "    \n",
    "    # print(\"\\nIn pruned model, number of nonzero parameters in each layer are: \\n\")\n",
    "    pruned_sum_params = 0\n",
    "    \n",
    "    for layer in pruned_model_stripped.trainable_weights:\n",
    "        # print(tf.math.count_nonzero(layer, axis = None).numpy())\n",
    "        pruned_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\n",
    "    \n",
    "    print(\"\\nRound = {0}, total number of trainable parameters = {1}\\n\".format(i, pruned_sum_params))\n",
    "    # print(\"\\nTotal number of trainable parameters = {0}\\n\".format(pruned_sum_params))\n",
    "    \n",
    "    '''\n",
    "    # Sanity-check: confirm that the weights are actually pruned away from the network-\n",
    "    print(\"\\nRound = {0}, % of weights pruned away = {1:.2f}%\\n\".format( \\\n",
    "                                                i, (orig_sum_params - pruned_sum_params) / orig_sum_params * 100))\n",
    "    '''\n",
    "    \n",
    "    # Save weights of PRUNED and Trained model BEFORE stripping-\n",
    "    pruned_model.save_weights(\"Conv_2_CIFAR_Pruned_Weights.h5\", overwrite = True)\n",
    "    \n",
    "    \n",
    "    # Create a mask:\n",
    "    \n",
    "    # Instantiate a new neural network model for which, the mask is to be created,\n",
    "    mask_model = pruned_nn(pruning_params_unpruned, pruning_params_unpruned)\n",
    "    \n",
    "    # Load weights of PRUNED model-\n",
    "    mask_model.load_weights(\"Conv_2_CIFAR_Pruned_Weights.h5\")\n",
    "    \n",
    "    # Strip the model of its pruning parameters-\n",
    "    mask_model_stripped = sparsity.strip_pruning(mask_model)\n",
    "    \n",
    "    # For each layer, for each weight which is 0, leave it, as is.\n",
    "    # And for weights which survive the pruning,reinitialize it to ONE (1)-\n",
    "    for wts in mask_model_stripped.trainable_weights:\n",
    "        wts.assign(tf.where(tf.equal(wts, 0.), 0., 1.))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extract Winning Ticket:\n",
    "    \n",
    "    # Instantiate a new neural network model for which, the weights are to be extracted-\n",
    "    winning_ticket_model = pruned_nn(pruning_params_unpruned, pruning_params_unpruned)\n",
    "    \n",
    "    # Load weights of PRUNED model-\n",
    "    winning_ticket_model.load_weights(\"Conv_2_CIFAR_Pruned_Weights.h5\")\n",
    "    \n",
    "    # Strip the model of its pruning parameters-\n",
    "    winning_ticket_model_stripped = sparsity.strip_pruning(winning_ticket_model)\n",
    "    \n",
    "    # For each layer, for each weight which is 0, leave it, as is. And for weights which survive the pruning,\n",
    "    # reinitialize it to the value, the model received BEFORE it was trained and pruned-\n",
    "    for orig_wts, pruned_wts in zip(orig_model_stripped.trainable_weights,\n",
    "                                    winning_ticket_model_stripped.trainable_weights):\n",
    "        pruned_wts.assign(tf.where(tf.equal(pruned_wts, 0), pruned_wts, orig_wts))\n",
    "    \n",
    "    \n",
    "    # Save the weights (with pruning parameters) extracted to a file-\n",
    "    winning_ticket_model.save_weights(\"Conv_2_CIFAR_Winning_Ticket.h5\", overwrite=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterative-pruning for Lottery Ticket Hypothesis is now complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIterative-pruning for Lottery Ticket Hypothesis is now complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/majumdar/The_Lottery_Ticket_Hypothesis-Resources'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/Pickle Python 3 dictionary-\n",
    "with open(\"/home/majumdar/The_Lottery_Ticket_Hypothesis-Resources/history_main.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history_main, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/arjun/Desktop/Codes/Lottery_Hypothesis-Resources/Latest_Works'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled Python 3 dictionary-\n",
    "with open('/home/arjun/Desktop/Codes/Lottery_Hypothesis-Resources/Latest_Works/Conv2_CIFAR_10_history_main.pkl', 'rb') as f:\n",
    "    history_main = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "history_main.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'val_accuracy', 'loss', 'val_loss'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check-\n",
    "history_main[12].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_main_info = {}\n",
    "\n",
    "# number of epochs per iterative pruning round BEFORE early stopping kicked in-\n",
    "num_epochs_early_stopping = [9, 9, 10, 7, 7, 7, 7, 7, 7, 8, 9, 8, 9, 12, 13, 18, 20, 23, 29, 24, 26, 32, 37, 33, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of parameters remaing AFTER (or at the end of) each\n",
    "# iterative pruning round-\n",
    "total_num_params_end_pruning_round = [3445303, 2759830, 2211106, 1771804,\n",
    "        1420073, 1138434, 912927, 732245, 587577, 471618, 378735, 304277,\n",
    "        244603, 196739, 158379, 127572, 102804, 82899, 66949, 54131,\n",
    "        43800, 35512, 28808, 23426, 19090]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of parameters before any pruning-\n",
    "orig_sum_params = 4301642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute % of weights pruned at the end of each iterative pruning round-\n",
    "percentage_wts_pruned = []\n",
    "\n",
    "for pruned_wts in total_num_params_end_pruning_round:\n",
    "    percentage_wts_pruned.append((orig_sum_params - pruned_wts) / orig_sum_params * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.90725867006134"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_wts_pruned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.9073% of weights are pruned\n",
      "35.8424% of weights are pruned\n",
      "48.5986% of weights are pruned\n",
      "58.8110% of weights are pruned\n",
      "66.9877% of weights are pruned\n",
      "73.5349% of weights are pruned\n",
      "78.7772% of weights are pruned\n",
      "82.9775% of weights are pruned\n",
      "86.3406% of weights are pruned\n",
      "89.0363% of weights are pruned\n",
      "91.1956% of weights are pruned\n",
      "92.9265% of weights are pruned\n",
      "94.3137% of weights are pruned\n",
      "95.4264% of weights are pruned\n",
      "96.3182% of weights are pruned\n",
      "97.0343% of weights are pruned\n",
      "97.6101% of weights are pruned\n",
      "98.0729% of weights are pruned\n",
      "98.4436% of weights are pruned\n",
      "98.7416% of weights are pruned\n",
      "98.9818% of weights are pruned\n",
      "99.1745% of weights are pruned\n",
      "99.3303% of weights are pruned\n",
      "99.4554% of weights are pruned\n",
      "99.5562% of weights are pruned\n"
     ]
    }
   ],
   "source": [
    "for wts in percentage_wts_pruned:\n",
    "    print(\"{0:.4f}% of weights are pruned\".format(wts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3 dict for training and testing accuracy visualization-\n",
    "plot_accuracy = {}\n",
    "plot_test_accuracy = {}\n",
    "\n",
    "\n",
    "# Python 3 dict for training and testing loss visualization-\n",
    "plot_loss = {}\n",
    "plot_test_loss = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate 'plot_test_accuracy' Python 3 dict-\n",
    "i = 0\n",
    "for k in history_main.keys():\n",
    "    epoch_length = len(history_main[k]['accuracy'])\n",
    "    # print(\"training accuracy = {0:.4f}%\".format(history_main[k]['accuracy'][epoch_length - 1]))\n",
    "    plot_test_accuracy[percentage_wts_pruned[i]] = history_main[k]['val_accuracy'][epoch_length - 1]\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "# Populate 'plot_accuracy' Python 3 dict-\n",
    "i = 0\n",
    "for k in history_main.keys():\n",
    "    epoch_length = len(history_main[k]['accuracy'])\n",
    "    plot_accuracy[percentage_wts_pruned[i]] = history_main[k]['accuracy'][epoch_length - 1]\n",
    "    \n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of training and testing accuracy VS percentage of weights\n",
    "# pruned-\n",
    "fig=plt.figure(figsize=(10, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(list(plot_accuracy.keys()), list(plot_accuracy.values()), label = 'training_accuracy')\n",
    "plt.plot(list(plot_test_accuracy.keys()), list(plot_test_accuracy.values()), label = 'testing_accuracy')\n",
    "\n",
    "plt.title(\"Conv-2 CNN: Accuracy vs. Percentage of weights pruned\")\n",
    "plt.xlabel(\"percentage of weights pruned\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate 'plot_loss' Python 3 dict-\n",
    "i = 0\n",
    "for k in history_main.keys():\n",
    "    epoch_length = len(history_main[k]['accuracy'])\n",
    "    plot_loss[percentage_wts_pruned[i]] = history_main[k]['loss'][epoch_length - 1]\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "# Populate 'plot_test_loss' Python 3 dict-\n",
    "i = 0\n",
    "for k in history_main.keys():\n",
    "    epoch_length = len(history_main[k]['accuracy'])\n",
    "    plot_test_loss[percentage_wts_pruned[i]] = history_main[k]['val_loss'][epoch_length - 1]\n",
    "    \n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAHnCAYAAACMvlSPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hUZfr/8c+kEUiFQBJICB0EaSIgvYmIiLB2XEAi5ivYkB+6KjbAhusqK67rgqIogmUFVFTWRRZQqkoHaQmgIfROAilTnt8fJxkIJJBIMjNJ3q/rmmvac865pxDuuZ9ybMYYIwAAAMAL/LwdAAAAACouklEAAAB4DckoAAAAvIZkFAAAAF5DMgoAAACvIRkFAACA15CMAgAAwGtIRgEAPuH7779XkyZNFBYWpieeeKLUj3fllVfqww8/LHL7xMREDRkypBQjKnueeeYZ9ejRw9thoIwjGUW5t2nTJg0aNEg1a9ZUaGio6tatq7vuuktr1671WkyHDh3SsGHDVK9ePXdMY8eOVXZ29iW3/eCDD9SxY0eFhYWpatWqatGihcaPH6+TJ09Kknr06CGbzaavv/4633ZDhgxRYmKi+35R2xWFzWbTwoULi7VNWfLbb7/JZrMpJCREoaGhqlGjhvr166dff/3V26FdVF7cKSkp3g6lSB566CElJSUpPT1df/3rX0v9eL/++quGDRtWYvsra+834CtIRlGuLVmyRO3bt1dMTIxWrlyp9PR0rV+/Xtddd50+//xzr8WVkZGhJk2aaOHChTp16pQWLlyob7/99pLVoJEjR+rJJ5/UqFGjtGfPHh0/flyzZ8/WkSNHtHHjRne76tWr69FHH1VOTs5F91fUdrBs2LBBGRkZ2rFjhypXrqz+/fv/4X3Z7fYSjKx82Llzp6666ipvh1GmGGPkcDi8HQZwWUhGUa6NGDFCt912myZPnqy6devKZrMpMjJSw4cP18SJE93tPvjgAzVv3lzh4eFq3rx5vq67vGrHhx9+qFatWiksLEwdOnTQli1bJEkLFixQeHi4Tp8+ne/YLVu21KRJkwqMq379+nrqqafUoEED+fn5qWHDhho+fLgWL15c6GtZsWKFpk6dqlmzZumuu+5SZGSkJKlJkyZ666231LVrV3fbxMREuVwuvfnmmxd9f4ra7nJkZWXpiSeeUL169VS1alV17dpVP/30k/v5DRs2qHv37oqMjFTVqlV19dVXa/v27ZKkxYsXq23btoqIiFBUVJQ6d+6s48ePX3CMkydPqkqVKlq6dGm+x0eNGqUBAwYUa19FUbVqVd1zzz367bffdPToUUnStm3b1L9/f8XExCguLk4PPPBAvu9E3bp1NW7cOPXt21dhYWF6/fXXJUkrV65Ur169VL16dVWrVk09e/ZUZmamJOnEiRO6//77VadOHUVFRalfv37atWuXe5+JiYkaNGiQHnroIUVFRSkmJkbPPvus+/krr7xSktSqVSuFhoZq5MiRkqR//vOf7u97bGyshg4dqiNHjri3s9vtevTRRxUbG6saNWpo7Nix6tKli8aPH+9us3fvXv35z39WXFycoqOjddddd+nw4cOFvmdOp1N/+9vf1LhxY0VERKht27b6z3/+I0nasWOHQkND5XQ6ddNNNyk0NPSCz1KSbr31Vo0dO9Z9v2fPnqpevbpcLpck6bPPPlODBg3czxflM5k2bZr7/vz589W8eXOFhoaqV69eGjdunOrWrZsvBofDUez3+6233lKDBg0UFhammJiYi/Y8JCYm6o477lBSUpIiIyOVkJCgV1991f183t+j9957T61atVKVKlW0evXqAocQ9OjRQ88884z7vs1m0z/+8Q917txZoaGhatGihZYtW5ZvmxkzZqhVq1aKiIjQlVdeqU8//TTf8x999JEaNWqksLAw3XLLLTpx4kShrwUoMgOUUzt27DCSzIIFCy7abvbs2SYsLMwsXLjQOBwO8/3335uQkBDzxRdfGGOM2b17t5Fkrr32WrNv3z6TmZlpbr31VtOtWzdjjDFOp9PUqVPHTJ8+3b3PVatWmaCgIHP48OEix3vDDTeYYcOGFfr8U089ZWrVqnXJ/XTv3t08/fTT5osvvjDh4eHm4MGDxhhjBg8enG//RW03a9YsExERcdFjSjLff/99gc899NBDpnnz5iY5OdlkZ2eb1157zYSGhpo9e/YYY4zp1KmTmTBhgrHb7cZut5t169aZAwcOGGOMqVWrlnn//feNy+Uy2dnZZsWKFSYjI6PA4wwdOjRf3JmZmaZq1armq6++Kva+zpf3HUhOTjbGGHPkyBFz8803m/r16xtjjDl8+LCpXr26mTRpksnKyjKHDx821157rUlKSnLvo06dOiYmJsasWLHCuFwuc/r0abN582YTHBxs3nrrLXP69GmTnZ1tFi9ebLKysozL5TI9evQwf/7zn83Ro0dNVlaWefzxx03Tpk1NTk6OMcaYYcOGmaCgIPPJJ58Yh8NhVqxYYQICAsyiRYsKjDvP7Nmzzfbt243T6TS//fabad++vRk0aJD7+QkTJpj69eubbdu2maysLDNu3DgTEBBgxo0bZ4wxJisryzRp0sQ8+uijJiMjw6Snp5shQ4aY3r17F/oevvbaayYuLs6sWbPG2O1288knn5jAwECzZs0ad5uLfY+MMeZf//qXadOmjTHGmIyMDBMSEmLq1q1rfv75Z2OMMffee68ZOXJksT6Td9991xhjTEpKigkMDDTvv/++sdvtZuXKlaZGjRqmTp067vZ/5P3esWOHqVy5stm0aZMxxpj09HTzww8/FPoahw0bZgICAsyUKVNMTk6OWblypalataqZOXNmvmN06tTJpKamGofDYbKyssywYcPM4MGD8+0r79/4ue9vy5YtTXJysrHb7eaRRx4xCQkJ7uenT59uateubX755RfjdDrN0qVLTVhYmFm6dKkxxpjly5ebgIAAM2/ePGO32828efNMcHCw6d69e6GvBygKklGUW8uWLTOSzJYtWy7ark+fPmb06NH5Hhs1apS5/vrrjTFn//if+x/IN998YypXruy+P2HCBNO5c2f3/aSkJHP77bcXOdbnn3/exMbGuhO0giQlJZn27dtfcl/n/gfUq1cvc++99xpjCk9GL9WuKApLIpxOp6lcubL58ssv8z3esmVLM3HiRGOMMT169DD33nuvSUlJuWD7unXrmqefftqkpaVdMoYffvjBVKlSxZw8edIYY8zMmTNNzZo1jcPhKPa+zpf3HQgLCzORkZEmLi7ODBw40P3dev31102HDh3ybbNs2TITFBTkPn6dOnXMk08+ma/Ngw8+aG688cYCj7lmzRoTGBho0tPT3Y85HA4THBzsTg6GDRtmevbsmW+7tm3bmldeeSVf3Ocno+ebO3euqVatmvt+gwYNzD//+c98x42OjnYno3PmzDG1atUyLpfL3SYtLc1IKvQ73LhxY/PGG2/ke2zAgAFmxIgR7vuXSkZ37txpbDabOXz4sPn6669N9+7dzahRo8wLL7xgjDEmISHBzJ071xhT9M8kLxl94YUXTLt27fK1f/TRRy9IRov7fu/atcsEBwebTz/91P3dvJhhw4a5E+48jz/+uOnVq1e+Y3z33XcXbFeUZPTDDz9039+8ebOR5P7x16JFCzNlypR8+0hKSnL/bUhKSjK33HJLvudvueUWklFcNrrpUW5FR0dLktLS0i7abs+ePfm69iSpYcOGSk1NzfdYrVq13LdDQkKUmZnpHqs1fPhwrVq1Stu3b9fp06f12WefKSkpSZI0a9YshYaGui/n7/fZZ5/VO++8oyVLlig+Pv6ir+dSr+V8kydP1kcffaR169aVSLviOnLkiDIzMy/6/n7wwQey2Wzq1auX4uPjNXr0aGVkZEiS5s2bp127dunqq69Ww4YNNW7cuELHx3Xr1k3x8fH65JNPJEnTpk1TYmKi/P39i72vwqxdu1bHjx9XWlqavvzySzVt2lSSlJycrDVr1igyMtJ96devn2w2mw4cOODevl69evn2t3v3bjVp0qTAYyUnJ8vhcCg+Pt69z6ioKEnWdzbPud9LyfpupqenX/R1zJ07V506dVJ0dLTCw8M1dOhQHTt2TE6nU5LVBV+nTh13e39/f9WuXTtfbAcPHlTVqlXdsV155ZWqVKnSBd/vPEX9d3Yx9evXV/369fX9999rwYIF6tOnj/r06aP//ve/2r59u/bu3atevXq5YyzKZ5Ln/Ncs6YIueqn473e9evX06aefavr06UpISFC7du3c39GLbXP+/XM/84LaFNX5f8ckueNPTk7Wo48+mu89++STT7Rv3z5J1t/SgmIDLhfJKMqtRo0aqXHjxvroo48u2q527drauXNnvsd27typhISEIh8rPj5effr00bRp0/Tpp5+qWrVq6t27tyRp8ODBysjIcF/y9muM0YMPPqhPPvlES5cuLTQpyXPjjTdq3759WrRoUZHjat68uZKSkvTII4+USLviql69uoKDgy/6/tapU0fvvvuufv/9dy1ZskTff/+9ezxvixYt9PHHH+vAgQOaPXu2pkyZounTpxd6vHvvvVfTpk1TSkqKfvzxR917773u54q7r+KIjY1Vly5ddOLECffl5MmTysrKUlxcnLudn1/+P7l169bVjh07Ct1nUFCQDh8+nG+/mZmZuuuuu4oU1/nHk6yE4vbbb9fDDz+s1NRUnTp1yv1vxBgjSYqLi9Pvv//u3sblcuX7IRQbG6s6derki+vEiRPKyspSp06dCoylJP6dSdJ1112nBQsWaMGCBbr++uvVo0cPrVu3TrNnz1b79u0VERHhjrEon0me81+zpAvuX0pB77ckDRw4UN99952OHDmiv/zlLxo8eHChn7tkjQs9//75P1TPP1ZYWNgF49bzksiiio2N1dtvv53vPcvIyND8+fMlWX/nCooNuFwkoyjXpk6dqs8//1xjxozR77//LmOMTp06pRkzZujpp5+WJCUlJen999/XkiVL5HQ6tWjRIr333nu67777inWspKQkzZgxQ1OnTtXw4cML/Y9JsiZBDBkyREuWLNHSpUsLrMCcr1OnThoxYoQGDx6sf//73+6lnFJSUjR69OgCJ3xI0vPPP6/Nmzfrv//970X3X9R2hbHb7crKysp38fPz0/Dhw/Xcc89p165dysnJ0d///nelpKRo8ODBkqzKaFpamowxCg8PV0BAgAICApSTk6Pp06e7J8VERETI399fAQEBhcYwbNgwbdiwQf/v//0/de/e3V2J+yP7Ko577rlH69at09tvv60zZ87IGKM9e/boyy+/vOh2999/v77//ntNmTJFmZmZstvt+uGHH5Sdna0uXbqoefPmuv/++3Xo0CFJ0vHjxzVnzhydOXOmSHHVqFFDfn5+7glhkrWSg8vlcv9QSE5OzjeZT5KGDh2qv//979qxY4dycnL04osvuidqSdItt9wiu92uZ5991v09PHTokD777LNCY0lKStJrr72m9evXy+Fw6N///rfmz5/v7kEoqj59+uiLL77Q0aNH1aZNG4WEhKh9+/b629/+pj59+rjbFfczGTRokNavX68ZM2bI4XDo559/1owZM4oVW0Hv9/bt2zV//nxlZGQoICDAnSznVewLsmHDBk2bNs0dx7vvvqt77rnnosdu27atFi9erG3btslut+uNN97Q7t27ixX/6NGj9cILL+iXX36Ry+VSdna2fvnlF61Zs0aS9e9r3rx5+vbbb+V0OvXtt9+6E1XgsnhzjADgCRs2bDB33HGHiY6ONiEhIaZOnTrmrrvuMmvXrnW3effdd03Tpk1NaGioadasmXnvvffczxU0Dmzx4sVGkrHb7e7HcnJyTExMjPHz87vo2E9jjFmyZImRZCpVqmRCQkLyXS7l/fffNx06dDAhISEmMjLSNG/e3EyYMME9Hu38cWLGGDN58mQjqdAxoxdrN3PmzEvGJanAi91uN2fOnDGPPfaYSUhIMBEREaZz585mxYoV7m3vvvtuU7NmTVOlShUTGxtrRowY4Z7M069fP1OjRg1TpUoVU7t2bTN27FjjdDovGsvNN99sJJlZs2a5H7vUvl566SXTrFmzQvdZlLGXW7duNX/6059MbGysCQ8PN02bNjXPP/+8+/lzxyeea+nSpaZbt24mMjLSVK1a1fTq1cucOXPGGGPMsWPHzMMPP2zq1q1rQkNDTe3atc3gwYPdzxdlnOArr7xiYmNjTUREhLn//vuNMcZMnDjRxMbGmtDQUNOxY0f35573fc7OzjaPPPKIiY6ONtWrVzdPPvmkadeunXucrzHWGNG7777b1K5d24SFhZkGDRqYBx54oND3x+FwmIkTJ5oGDRqYsLAw06ZNG/P111/na6NLjBk1xpgTJ06YgICAfBOuXnnlFSPJLF++PF/b4n4mX3/9tWnatKkJCQkxPXv2NE8++aRp0qSJ+/k/8n5v3LjRdOrUyYSHh5uwsDBz5ZVXmo8++qjQ1zds2DBz++23m3vvvddERESY+Ph48/LLL7vH5xb2XbTb7WbEiBGmatWqJiYmxowbN67AMaPnvr8F7WvmzJmmTZs2JiIiwkRFRZnu3bvnGy8/ffp006BBAxMaGmpuvvlm8+CDDzJmFJfNZkxuvwwAAAVwOByqWbOm3nzzzSIPESgPRo8era1bt/7h3oI/IjExUQ6HQzNnzvTYMQFvo5seAJBPenq6vv76a+Xk5CgjI0NPPPGEXC6XbrjhBm+HVqq++eYbHTlyRE6nUwsXLtT777/vHk4CoPSQjAIA8nG5XHrhhRdUvXp1xcXF6eeff9b8+fPdJ1oor1auXKmmTZsqPDxc999/v5577jkNHTrU22EB5R7d9AAAAPAaKqMAAADwGpJRAAAAeE3JLLLnRZUqVVKNGjW8HQYAAAAKcfjwYWVnZxf4XJlPRmvUqFHsUyQCAADAcy52umu66QEAAOA1JKMAAADwGpJRAAAAeE2ZHzN6KS6XSyyl6vtsNpv8/PhtBABARVNuk9GcnBylpqbKbrd7OxQUUWBgoBISEhQUFOTtUAAAgIeU22Q0NTVVYWFhioqKks1m83Y4uARjjI4eParU1FQ1bNjQ2+EAAAAPKZfJqMvlkt1uV1RUlAICyuVLLJeioqJ07NgxuVwuuuwBAKggyuX/+HljRKmIli15nxdjfAEAqDjKZTIKAACAsoFkFAAAAF5DMuoh48ePV1ZWVrG327dvn7p27Vqktv369dP27duLfYyiqFu3rtavX18q+wYAABVXhZjdk/ThL/r96JlS2XedqCqaNqzdJdtNmDBBo0ePVnBwcL7HHQ7HRSdZ1apVS0uXLi1SLPPnzy9SOwAAAF9BZdQDRo4cKUnq2rWrWrdurX79+mn48OHq1q2bmjdvLkkaPHiw2rZtq5YtW+rGG2/UgQMHJEm//fabIiMj3fuy2Wx6+eWX1b59e9WrV0/Tp093P3du9bJHjx567LHH1LVrVzVo0MAdgyTt379fffr0UbNmzdSnTx8NGjRI48ePL/LrSUlJUe/evdWyZUu1bt1aX375pSQpMzNTd955p5o1a6ZWrVqpT58+kqTk5GR17txZrVq1UosWLfTMM8/8gXcRAACURxWiMlqUymVpmjJliqZOnaqlS5cqMjJSiYmJWrNmjZYtW6awsDBJ0htvvKEaNWpIkl555RWNHz9eU6ZMKXB/lSpV0s8//6xt27apXbt2Gjp0aIHV1Z07d2rx4sWy2+1q1qyZVq5cqY4dO2rUqFHq2LGjJkyYoAMHDqh169a64oorivx6Bg8erOHDh2vEiBFKTk5Whw4ddNVVV2nt2rU6ceKEtmzZIkk6duyYJOmtt95S//79NXbs2HyPAwAAVIhk1Bfdfvvt7kRUkj7++GN99NFHysrKUlZWlqpXr17otoMHD5YkXXHFFQoICNCBAwcUHx9/Qbs777xTAQEBCggIUOvWrbVz50517NhR//vf//Taa69JkmJjY9W/f/8ix52enq61a9dq+fLlkqRGjRqpS5cuWrp0qTp16qStW7fqgQceUPfu3dWvXz9JUrdu3fSXv/xFGRkZ6t69u3r37l3k4wEAgPKNbnovCQ0Ndd9etmyZ3nzzTc2fP1+bN2/WpEmTLjrZ6dxxp/7+/nI4HJfV7nLXY83bvn79+tqyZYv69u2r5cuXq3nz5jp+/LhuvfVWLV++XE2aNHFXSQEAACSSUY8JCwvTyZMnC3zu+PHj7lOX5uTkaOrUqaUaS69evfTBBx9Ikg4ePKhvvvmmyNuGhYWpTZs27rGqKSkpWrZsmbp166a0tDTZbDYNGDBAr732mowx2rNnj5KTkxUTE6O7775br776qlatWlUaLwsAAFyKI0eakyStnn7pth5CN72HPProo7ruuutUpUoV1apVK99zffv21cyZM9WkSRNFRUWpd+/e2rt3b6nFMnnyZA0bNkzNmjVTrVq1dM011+SbJHUps2bN0siRI/XWW2/JZrNp2rRpSkhI0H/+8x+NHTtWxhg5HA4NHTpULVu21MSJEzVz5kwFBQXJ5XIVOhYWAACUMkeWtOlzyb+S1PYeb0cjSbKZMn7uxfj4eKWlpeV7zOl0aseOHWrcuLH8/f29FJnvyszMVGBgoAICAnT06FF16NBBM2fO1DXXXOPVuPjcAAAoZWeOSa/Wk65OlG6a7LHDFpSv5aEyWgElJyfr7rvvljFGOTk5euCBB7yeiAIAAA9w2q1rv0DvxnEOktEKqGXLlgWeTen555/X3LlzL3h8zpw5atCggSdCAwAApcmVm4z6k4zCBz333HN67rnnvB0GAAAoLe7KqO+kgMymBwAAqChcucs8+lBllGQUAACgovDBMaMkowAAABWFe8wo3fQAAADwNGduNz2V0Ypn/PjxFz3FZ3G3f+655zRr1qySCO0CiYmJeuONN0pl3wAAwIt8cDY9yaiHTJgw4bKS0fO3f/755zV48OCSCA0AAFQUPjhm1HcGDJSmjwdJx3eXzr6r1pP+/OlFm4wcOVKS1LVrV/n7++urr77Siy++qA0bNigrK0sdOnTQW2+9paCgIL344ouaNWuWKlWqJEn66quvNHHixHzbL1iwQI8//rhat26t0aNHa/z48dq6davOnDmjnTt3KjY2VrNnz1a1atVkt9v1yCOPaOHChapWrZo6d+6sNWvWaMmSJUV6eRkZGRo1apR+/vlnSdLtt9+ucePGSVKBsUZHRysxMVGbNm1SYGCgYmJitGDBgmK/rQAAoBT44JhR34mkHJsyZYqmTp2qpUuXKjIyUvfdd5+6du2qd999V8YY/d///Z8mT56spKQkvfbaa9q/f78qV66sM2fOyM/P74LtC/LTTz9pzZo1ioqK0qBBgzR16lSNHTtW77zzjpKTk/Xrr79Kkvr161es2F944QVlZ2dr48aNyszMVJcuXXTFFVeoT58+Bcb6n//8RydOnNCWLVskSceOHbu8Nw8AAJQcHxwzWjGS0UtULj3tyy+/1MqVKzVp0iRJ1rni/f39FR4erkaNGmnIkCHq06ePbrzxRsXHxxdpn3379lVUVJQkqWPHjtq0aZMk6X//+5+GDBmiwEDrSzds2DBNmzatyLEuXLhQr7/+uvz8/BQSEqK7775b33//vW677bYCY23VqpW2bt2qBx54QN27dy928gsAAEoRY0YhScYYzZkzR+vXr9f69eu1fft2TZ06Vf7+/lq1apVGjx6tQ4cOqUOHDlq6dGmR9hkcHOy+7e/vL4fDUWA7m812WbHnbV9YrPXr19eWLVvUt29fLV++XM2bN9fx48cv65gAAKCEcAamiissLEwnT56UJP3pT3/SX//6V3fCePz4caWkpCg9PV0HDx5U165d9eyzz6pLly5at27dBdsXR69evfTxxx/LbrfLbrdrxowZxdq+d+/eeu+992SM0enTp/XRRx+pT58+hcaalpYmm82mAQMG6LXXXpMxRnv27Cl23AAAoBT44BmYfCctLuceffRRXXfddapSpYrmzZunV199Va1bt5afn58CAgL06quvKjg4WLfddptOnz4tm82mRo0aadiwYRdsX5wJQSNGjNCmTZvUrFkzVa1aVW3bttW+ffuKvP2zzz6rUaNGqUWLFpKsCUx33HGH0tLSCox1xYoVGjt2rIwxcjgcGjp0qFq2bFm8NwsAAJQOH5xNbzPGGG8HcTni4+OVlpaW7zGn06kdO3aocePG8vf391JkviM9PV1hYWGy2+0aPHiwrr76aj3xxBPeDusCfG4AAJSytTOkeQ9Lg2dLja7z2GELytfyUBmtAHr37q3s7GxlZWWpS5cuGjVqlLdDAgAA3uDMsa59aMyo70SCUvPTTz9d8Nj8+fP11FNPXfD42LFjdeedd3oiLAAA4GlOxozCR/Tr149llwAAqGhcvjdmtFzOps9bfqiMD4etcPI+r8tdfgoAABTC6XvrjJbLyqifn58CAwN19OhRRUVFkdyUAcYYHT16VIGBgfLzK5e/kQAA8D6WdvKchIQEpaamcjrKMiQwMFAJCQneDgMAgPLLB5d2KrfJaFBQkBo2bCiXy0V3fRlgs9moiAIAUNp88HSg5TYZzUOCAwAAkIvTgQIAAMBrfHDMKMkoAABAReGDY0ZJRgEAACoK95hRuukBAADgaXlnYKIyCgAAAI/zwdn0JKMAAAAVBWNGAQAA4DUuh2Tzk3xo6UvfiQQAAACly2n3qaqoRDIKAABQcbjsPjVeVCIZBQAAqDicdp86+5JEMgoAAFBxuBxURgEAAOAlLgdjRgEAAOAldNMDAADAa1xOnzoVqEQyCgAAUHG4HFRGAQAA4CUuuukBAADgLRWxMjpq1CjVrVtXNptN69evL7DNokWL1L59ezVr1kxXXnmlHn/8cblcrtIODQAAoGJxVsBk9LbbbtOyZctUp06dQttUrVpVn376qbZs2aI1a9ZoxYoVmjFjRmmHBgAAULH44DqjpZ4ad+vW7ZJtrrrqKvft4OBgtW7dWr/99lspRgUAAFABVcRu+uI6cOCAZs+erf79+xf4/KRJkxQfH+++ZGRkeDhCAACAMooJTBd36tQp3XTTTXr88cfVtm3bAmzAehYAACAASURBVNuMGTNGaWlp7ktoaKiHowQAACijXE6S0cKkp6erb9++GjhwoMaMGePtcAAAAMofzsBUsIyMDPXt21d9+/bVM8884+1wAAAAyicfnMBU6snoiBEjFB8fr7S0NF1//fVq2LChJCkpKUnz5s2TJE2ePFk///yz5s6dq9atW6t169Z66aWXSjs0AACAisMYyTglP39vR5KPzRhjvB3E5chLdAEAAHARTrv0QnWp+W3Sbe959NAXy9d8opseAAAApczlsK4ZMwoAAACPc9qta5JRAAAAeFxeZdSfZBQAAACe5nJa11RGAQAA4HGuvG76Cra0EwAAAHyAewKTby3tRDIKAABQETCBCQAAAF6TN2a0op2BCQAAAD6AdUYBAADgNS666QEAAOAtVEYBAADgNc68Re8ZMwoAAABPozIKAAAAr2GdUQAAAHgNZ2ACAACA13BuegAAAHhN3hmYmMAEAAAAj2PMKAAAALyG2fQAAADwGncySjc9AAAAPI3KKAAAALzGPYGJZBQAAACeRmUUAAAAXuNeZ5QxowAAAPA09xmYqIwCAADA01hnFAAAAF7jzE1GOQMTAAAAPI4JTAAAAPAaFr0HAACA17gnMDFmFAAAAJ7mXtqJbnoAAAB4mvsMTHTTAwAAwNOYwAQAAACvIRkFAACA15CMAgAAwGtIRgEAAOA1OadlbH76fscJ/brvpLejcSMZBQAAqAhyMqSgUP3fR2v0/rLfvB2NG8koAABARZCdLlMpTJLk70MZoA+FAgAAgFKTnSETGCpJ8vezeTmYs0hGAQAAKoLsdLmCrGTUz0YyCgAAAE/KTpcJojIKAAAAT3O5pJwMuQKtMaNURgEAAOA59tOSjJxBIZKojAIAAMCTsjMkSS4mMAEAAMDjstMlSU666QEAAOBx7mQ0r5vem8Hk50OhAAAAoFTk5CWjud30VEYBAADgMbmVUUeAVRn1Y8woAAAAPCZ3ApM9r5ueyigAAAA8Jm/MqH/uGZiojAIAAMBjcseMuiujJKMAAADwmNzKqD2ACUwAAADwNHcyWkUS3fQAAADwpNwJTDn+eZVRbwaTH8koAABAeZedLtn85bQFSWLMKAAAADwp87gUHC5n7l266QEAAOAZLpd0cLMU3UxOl5HEBCYAAAB4ytFkKfuUFNdGLmMlo1RGAQAA4Bl711jXcVfL6bJu+lEZBQAAgEekrbau49q6K6P+PpQBBng7AADlSOYJ6dhO6ehOyS9AanqT5B/o7agAoGLbu0YKiZYi4uXac0CSb1VGSUYBFI89Uzq2WzqaknvZefb2mSP521atK3V/Ump5h+Tn75VwAaBCy063Ji81vE6y2eR0V0ZJRgH4MqdDOpmaP9E8miId3SWd3CPJ5G9fuZoU1VBq1EeKamDdPpIsrfyH9OVIaenrUo8npStvkfx8qG8IAMobY6S591kFgL6vSAvHSS6H1KSvJPnkbHqSUaCiMkZKP3BesrnT6mY/tlty2fO3D6xiJZrxV1vJZt6lWn2pSrWCj9H+/6SV/5RWvS3NuVdaOknqOVa6or/kQ38IAaDc+H25tOnf1u2di6SMg1K97tJVd0uST86mJxkFyrvM4+dVOHeevbafzt/WL0CqWk9q2Du3wtngbNIZVrP4CWTlSKnX09I1I6UVk6Wf3pE+GyLVbCX1fEZqdB1JKQCUpJVvW9fdn5CWT5aCI6U//cvdK5U3m57KKICSlXNGOrbrbMJ57u0zRy9sH1Fbqt0ut7KZl3A2kCLrSP6l8GchJEq67nmpw4PSsr9Lq9+XPr5dim8n9Xxaqt+DpBQALtexXdL2+VLjvlLPp6Srhli9YBFx7iYuF2NGy7at30gn06xqT3CE9Wvj3NuBlfkPFaXHaZdOpF44aejoTulU2oXtq1S3kszGffNXOKvWk4KqeD5+SQqLkW54Rer0sLT0NWntR9JHf5LqdLEqqHU6eScuACgPfpoqyUgd7rfuRyZc0MRJN30Zt36W9YujMP5BVlIaHJGbpBbxduVIKSiMiR2wfsGe2pe7PNJ5Sefx36xB6OcKCrXGbNZun38cZ1R9qXJVr7yEIomIk/r/Xeo8WvrxVWn9J9L0G6T6PaVez0jxbb0dIQCULVknpXUzpegrrTGihaiQE5hGjRqlefPm6ffff9e6devUunXrAtu99957euWVV+RyudSrVy+9/fbbCgz0sfUJr39J6viQlHXCWk8x64T14Rd0+2SadGCz5Mgs2r5tflKl8MKrrhfcrnpOQhvBWo5lzZljBcxUz508ZD+Tv61foFStXv6Z6nmX0JiyXY2vWkca+E+pyxhpySvSps+lXYvPdjHVbOXtCAGgbFg3S8rJsKqiF/l/4ewEJk8Fdmmlnozedtttevzxx9WlS5dC2+zevVvPPvus1q5dq5iYGA0cOFDvvPOOHnzwwdIOr3iq1bcuxeHIzk1QT56TxJ48L6E97/Ezx63ZzNmnin6cwJDCq66XSm4ZXlA6ck7nH7t5bvKZefy8xrbccZzXnFfhbGA9XhrjOH1JVAPp1nelrmOkJROlLV9JO76Tmg6wktLopt6OEAB824ZPrKJWi9su2qxCVka7det2yTazZ8/WgAEDFBsbK0kaOXKkXn75Zd9LRv+IgErWOLmwmOJv63KeTVDPrbpeNLk9KR05YN02zqIdxz/ovCS1GEMNKoX71s8rT3PapeO/n1fhzE080/dd2D6khlTjirMVzrzJQ9XqWT8KKrroptIdM6T9G62kdOs8aevX1h/X7k9K1Rt6O0IA8D2Hd0gHNkqth1zy/xInE5gKlpqaqjp16rjv161bV6mpqQW2nTRpkiZNmuS+n5GRUerxeY2fv7V+Y2FrOF6MMVa5vrBhBIUltyf2SFmlObzgvIptWRhe4HJZiWVBFc7jv1+Y9AeFWclmnU7ndKs3sBLPypHeeQ1lTc2W0l2fSGlrpMUvWd33m+dKre6Suv/FOrMTAMCyebZ1fYmqqMQ6oyVizJgxGjNmjPt+fHy8F6PxYTabVCnMukT8gfeowOEF5ye0pTi8oChDDUpyeIExueM4z6twHttlJZ/nJ+f+QdaQjfNnqkc1lEKjGfZQUuKvlobOlX5faSWl62dKGz+VrhoqdftLvuVKAKBCMkbaNNs693y9S/dGs85oIRISErRz5073/d9++00JCRcuRwAPupzhBU6HlZBeckjBecntZQ8vKOJQg6wT51Q4z6lyZp047wA2KbK2VKdj/jGcUQ2tcZyca91z6nSUEr+Rdv1gJaVrpkvrP5ba3mNNfvoj31MAKA/2rbMmv14zskj/L7k4N33Bbr31VnXp0kXjx49XTEyMpkyZokGDBnk7LPxR/gElO7zgUmNk3cMLNkmOrOIfMyRaim52YYWzal0pMLj4+0Ppqd/d+uWfslBa9KL00xRpzYfWaUc7j7YW1weAimTzHOu6xe1Fap43ZtSvIlVGR4wYoW+//VYHDhzQ9ddfr7CwMKWkpCgpKUkDBgzQgAEDVL9+fU2YMEGdO3eWJPXo0UMjRowo7dDgiy53eIE9q+BJX+feDgqVqjc6O44zOLzkXwdKj81mnUa0YW9r3d9FL0kr3rTO6nTNSKnTQ769xioAlBSX00pGq9aV4q4u0ia+OIHJZkxuvbaMio+PV1paAWefAVAxuFzSli+t2fdHdkiVIqyE9JqR/NAAUL7t/lH68Cap62PStc8WaZPXF2zXPxalaOGYbmoYHVbKAZ51sXytAq/JA6Bc8POTmt8iPbBKunmqNTxk8UvS5JbSsjes9V4BoDza9Ll1XcQuesk3u+lJRgGUD37+UqtB0kO/SAP+YQ3HWDhOmtxKWvm2NYQDAMqL1J+ssy7VukqKvqLImzl9cAITySiA8sU/UGpzt/TwGqnfa5JfgPTfsdKbV0m/TJMcOd6OEAAuz5lj0uzh1qoyA98u1qYuKqMA4CEBlaxZ9qPWSde/LDlzpG8flf5xtbT2I2sJMgAoa4yRvrxfOpUm9fubFNOsWJu71xmlMgoAHhJYWer4oPTIBunacdYauPMekv7ZTtrwmTUbFQDKipVvSTu+k1reKV01pNib++I6oySjACqGSqFS1zHS6I1Sj7HS6SPSF/dJb3eUfv3CmpUPAL5szy/SwvFSVCPpxkl/6Gx/TGACAG8LjpB6PGlVSrs+Kp1Mkz5PlKZ2k7bNt7rAAMDXuJzSFyOscfB3fGj9wP4DmMAEAL6iSjXp2uesSmnHh6SjydKnd0nv9pKSF5KUAvAt2+dbp/3s9LAUc+Uf3k3e8vI+lIuSjAKo4EKqS9e/ZFVK298nHdwszbpVer+vtaA0APiClW9bs+fb/d9l7cbdTe9D2SjJKABIUlisNTP14bXS1YnS3tXWmU0+6C+lrvJ2dAAqsn3rpNQVUvPbpLCYy9qVezY9Y0YBwEdF1pZumiw9tFpq9Wfp9+XS+9dLM2+V9q71dnQAKqJV/7KuO9x/2btiNj0AlBXV6kk3/0t68Gep+a1Syv+kd3tKn/xZOrDZ29EBqChO7Zc2z5XqdpVqtrzs3TGbHgDKmuqNpNvel+5fITW9Sdr+rTSlszUD//B2b0cHoLz7ZZrkspdIVVRiNj0AlF0xzaQ7Z0r3/SA1ut5am/TtDtLcEdLRnd6ODkB5ZM+UVr8vVa0rNe5bIrs8ezrQEtldiSAZBYDiqNVaGvxv6d6FUr1u0sZPpbfaSV89JJ1I9XZ0AMqTjZ9Jmceka+6X/PxLZJdOl5GfTbLRTQ8AZVztdtLdX0mJ86Xa10jrPpLebCN9+6h0ap+3owNQ1hljTVyqFC5dNbjEdusyxqe66CWSUQC4PHU7S/fMl4Z+IdVsZY3vmtxa+u4pKeOwt6MDUFbtXCQd3ia1uVuqFFZiu7UqoySjAFC+2GxSg15S0kLpz/+WajSRVv1TmtxS+n6cdOaYtyMEUBa4XNKRFGnTbGnRC5LNzzoZRwlyGt+avCRJAd4OAADKDZtNany91PA6ads30uKXpeVvSL+8J3V8QOrwgFQ50ttRwpcYIzmypKxTUtZJKTv3Ot/tU9bt7HQpqqH1w6dmqxIbQwgvsmdKW7+R9q2V9q2XDmyUcjLOPt9mmFS1Toke0uUyPrXgvUQyCgAlz89PajZAuuJGa9b9konSD3+VfpoidRolXTNSqhTq7ShREpyOs0njucmj+37e7ZP5E8tzbztzinfMRS9IlatK9XtI9XtayWlk7dJ4dSgtWSetIT2r/iWdzh3OUylcqtnamiRZs5V1iWpU4od2uoxPnQpUIhkFgNLj5y+1uE1q9idrVuwPf7USiVVvS50elup2s7r0SUx9hyNHOvSrtH+jdObIhcnj+Umm/XQxdm6zEo7gcCk4QgqNPXu7Uu51cHj+28GRZ7cJrCzt32CNJdy5WPr1S+vHjnS2Ylq/p1S3i9UeRedyWj8KAiuX7nEyDln//n95z/oehcdLfV+RGvWRqtazfsiWMqcPTmCyGZO7+mkZFR8fr7S0NG+HAQCX5siR1s+SfvybdGrv2ccjaltJaY0rzrk0IaEobS6XdDTZOs3r3jVWV+mBzZIzu+D2AZULSRgjzkkyI/MnnOe2Cwor2WTj9FFp95Lc5HSJdCr3/0K/ACm+3dnktNZVkn8FqD2dOWadvjfrlJRzWspJt66zMy5935Fp7aPBtVKvp6W4q0s2tuO/SyvelNbNtIZlVG8sdR4ttbhdCggq2WNdwm3/WqHfjp7R6md6e/S4F8vXSEYBwNPsWVLKQunQVmu27OHt0pEdFyZB4XG5SWrTc5LVJow7/SOMkU7usZLOvWulfeusMXo56WfbVK4mxbWRarWxErjwmmeTyUrhHk8aisUY6UiytGuxlZz+tuzs2MPgCGtN3LzktFo978ZakoyRUldJa6ZbleLCfkjkCawiBYVKQSFWj0RQ6Nn79kwpeYEkIzXpJ/V8SoptcXnxHd4hLX1d2vS5ZJzW96rLGOmK/h6pghbk5reXa9+JTP30FMloiSEZBVAuOB3Sid+t5PTQVitBPbzNSlIdWfnbhtW8MEmNvsIaRwhLxmGr0rl37dnrM0fOPh8YYo3Nq3WVVQWLayNF1rEmoZUHjhxp7+qzXfr71krGZT1XtZ7UoKeVmNbrVjZ/3GSesIa+rJ4uHd5qPZbQUWp5pxQWayWY5yebQSGXnvR1aKs18XDrPOt+s4FSj6esf1/FcWib9OOr1jnlZaz3ucsYa5yvl79jA99apsPp2Vox9lqPHpdkFADKKpczN0ndfmGSaj+Tv21oTP4kNbqplahWqead2D0l65S0f/053e3rrCpoHr9Aq8KVV/WMa2N1k1ak2eiZx6XdP+Ymp4vOni3M5mcl43lV0/i2kn+gd2MtjDHWZ7z6fWnzHKtrvVKE1GqQ1PYe6/teUvZvkBZPlHb8R5LN6k7v8aQU1eDi2x381RqG8+uXkozV7d/jSal2+5KL7TL1/8dSnThj17Inenn0uCSjAFDeuFzSydSzyemhbWe7/M+fVBNSI/9Y1LwkNaS6d2K/HPYs6cCm/FXPI8mS8v4rs1mvLS63qz2ujRTTXAqo5M2ofYsx0rFduV36i60kNfuU9VxQmFSv69nkNKqB1yt5yk63urlXv2999pIU19ZKQK+8RQqqUnrHTlstLX7JSuBt/lKru6Tuj1+43NKBzdYExbyKaqM+UvcnrOTex9wweanO5Dj0w196evS4JKMAUFG4XNZEloKS1HPHR0pSlagLu/prXGElr95OQCRr6MLhbfkTz4O/Si7H2TaRdc6peF5tLYfD6gTF43RYFeW88aZpq63xjZIUkSDV72YtMRSZYL3fkQnWD5nS/o7s32B1w2/63Br/GhQqtbxDuvoeqWbL0j32+X5fIS16Sfp9mVVpbzNU6vqYNfTjh1etdYUlqfENVrIa18az8RXD9X//UXanS4se6+HR45KMAkBFZ4w1gz8vMT23yz+vKpanctWCk9TQmNJLQPKqdfvWne1uP7Ax/1CEkOiz4zvzJhmFRJVOPBVZ1klp99KzyemxXRe2Caicm5yef7nMZDXntDXOcs106zsgSbEtpbbDrWXSSvC0mMVmjLT7ByspTfvZSkpdduu5K/pL3f5ijUP2cb0n/SBJWjimu0ePe7F8rQKs9QAAkM0mRcRbl4bnzKI1Rkrff2GSeuhXKXVF/n0ER57t6j83SQ2rWfzE49T+s8sp5c1uzzpx9vlKEdbyROeO8wyP842KbXkXHCE17W9dJCn9oDVu+UTqOde5l90/FjyDvbjJ6sEtVgK64VPrx1FgFemqoVZXfK02vvG522zWBKR63a3VMFb8wxqP3WWM5yu1l8HlMgr0962zwZOMAkBFZrNJ4bWsS4NzJjQYI2UcLKCSulXasyr/PipF5Cao5yWpecnjmWO5SymtlfbmXqfvP7t9QLBV/YrL7Wqv1UaqVt9rS9/gPGEx1qWgSTgul3T60DkJ6h9IVrNOWpVGSYpuZlVBW95hJcW+yGaTGl1nXcogpzGq5GOL3pOMAgAuZLNZS+SExVrVoDzGWKcvLKi7Py+hyBMUZnX5n0w9Z7/+VsLRqM/Zqmd0U9+dwY2L8/M7+z35o8mqJLUcZCWhtdv7RhW0HHO6jHysMEoyCgAoBptNCo22LvW65X/u9JHcJPWcRPXMUanFHWcTz9gWpTv7Gb6lKMmqy+HbJxQoZ4yR/H0s4ScZBQCUjJDqUkgX69zoQFH4+Ul+JKKe5HQZ+flYN72PFWoBAABQWpzG+FxllGQUAACggnBRGQUAAIC3OI2Rj+WiJKMAAAAVhTWb3reyUZJRAACACsLlMvJjzCgAAAC8wWmojAIAAMBLXC7fW2eUZBQAAKCCcBpm0wMAAMBLnC7WGQUAAIAXuFxGkhgzCgAAAM9zGisZpZseAAAAHufMq4z6Vi5KMgoAAFARuKiMAgAAwFvOVkZJRgEAAOBhLpd1zQQmAAAAeBwTmAAAAOA1dNMDAADAa/ImMNFNDwAAAI/Lq4z6URkFAACAp7m76X0s+/OxcAAAAFAayvw6o88995xOnDghY4xuvPFGVa9eXXPmzCnN2AAAAFBCcgujZXcC01dffaXIyEgtXLhQAQEBWr58uV588cXSjA0AAAAl5Gw3fRlNRv38rKY//PCDbr/9djVp0kQ2H8usAQAAUDB3N72P5W8BRW0YEhKiv/71r/r000+1fPlyGWOUk5NTmrEBAACghJT5yugHH3yg/fv369VXX1VMTIx27typIUOGlGZsAAAAKCG+mowWuTLasGFDvfHGG5KkkydPKisrS08++WSpBQYAAICS46vd9EWujPbt21cnTpxQRkaGWrVqpf79++u5554rzdgAAABQQsr8OqMHDx5UZGSk5s+fr4EDByo5OVlffPFFacYGAACAElLmK6N2u12S9OOPP+q6665TYGCgAgKK3MsPAAAAL3K6rGtfGzNa5GS0efPmuuGGG/TNN9+oV69eOnPmTGnGBQAAgBJU5icwffDBB/ruu+/UqlUrValSRXv37tXEiRNLMzYAAACUkDLfTR8cHKyrr75aK1eu1McffyxjjPr27VuasQEAAKCE+GpltFinA73qqqv0+eef6/PPP1ebNm309ddfl2ZsAAAAKCFOd2XUy4Gcp8jd9BMmTNCqVavUsGFDSVJKSoruuOMO3XTTTaUWHAAAAEqGy1XGu+mdTqc7EZWsRfBdLtclt0tOTlanTp3UuHFjtWvXTr/++usFbVwul8aMGaNmzZqpZcuW6tmzp1JSUooaGgAAAC6hzHfTR0dHa9q0aXK5XHK5XHrvvfdUo0aNS243YsQI3XfffdqxY4eeeOIJJSYmXtBm3rx5Wr58uTZs2KCNGzfq2muv1VNPPVWsFwIAAIDC5U1gKrPJ6JQpUzRt2jRVrlxZlStX1rRp0zRhwoSLbnPo0CGtXr3afQ77W2+9VXv27Lmg6mmz2ZSdna2srCwZY3Tq1CnFx8f/gZcDAACAguStM+pr3fRFHjPaoEEDrVq1ShkZGZKk0NBQJSQkKDU1tdBt9uzZo5o1a7oXx7fZbO5tzu3yv+mmm7R48WLFxsYqLCxMcXFx+uGHH/7oawIAAMB5nGW9MponNDRUoaGhkiST+6Iu1+rVq7V582bt3btX+/bt07XXXquRI0cW2HbSpEmKj493X/KSYwAAABSuzE9gKojtEi+mdu3a2r9/vxwOhyQreU1NTVVCQkK+djNmzFCvXr0UGRkpPz8/DRs2TIsXLy5wn2PGjFFaWpr7kpcYAwAAoHC+OoHpkt30GzduLPS5vPPVFyY6Olpt2rTRzJkzlZiYqDlz5ig+Pj5fF70k1a9fX/Pnz9djjz2moKAgffPNN2revHkRXwIAAAAu5Ww3vZcDOc8lk9GBAwcW+lzlypUveYCpU6cqMTFRL7/8ssLDwzV9+nRJUlJSkgYMGKABAwbowQcf1NatW9WqVSsFBgYqNjZWU6ZMKcbLAAAAwMX4ajf9JZPR3bt3X9YBmjRpopUrV17w+LRp09y3K1WqpHffffeyjgMAAIDClZsJTAAAACh7cguj8vexyijJKAAAQAXg7qanMgoAAABP89XZ9CSjAAAAFUDe6UB9bQITySgAAEAFQGUUAAAAXuOeTU9lFAAAAJ52dgKTlwM5j4+FAwAAgNLgdFnXdNMDAADA4+imBwAAgNewzigAAAC8hsooAAAAvMbF0k4AAADwFifd9AAAAPAWuukBAADgNawzCgAAAK+hMgoAAACvYdF7AAAAeA3rjAIAAMBr6KYHAACA17DOKAAAALwmrzLqY4VRklEAAICKIDPHKX8/m4L8fSv9861oAAAAUCrO5DhVJchfNh8rjZKMAgAAVACncxwKCQrwdhgXIBkFAACoAM5kO1Wlkr+3w7gAySgAAEAFQGUUAAAAXpM3ZtTXkIwCAABUAKezHQqtRGUUAAAAHuZwupTtcKkKySgAAAA87XSOU5IUQjc9AAAAPO1MjkOSVIUJTAAAAPC009m5lVGWdgIAAICnURkFAACA11AZBQAAgNdQGQUAAIDXMJseAAAAXnMmO7cyyjqjAAAA8DQqowAAAPAad2WUMaMAAADwNHdllNn0AAAA8DRm0wMAAMBrMnK76amMAgAAwOPOZDtls0nBASSjAAAA8LDTOQ5VCfSXn5/N26FcgGQUAACgnNt/MkvVwyp5O4wCkYwCAACUY1l2p3YfOa0mMWHeDqVAJKMAAADlWMqhDDldRlfUDPd2KAUiGQUAACjHth9IlyRdEUtlFAAAAB627cApSVITklEAAAB42rYD6aoU4Ke6USHeDqVAJKMAAADl2LYD6WocEyZ/H1zWSSIZBQAAKLcOpWfpcHq2z3bRSySjAAAA5db/th6SJHVqEOXlSApHMgoAAFBO/WfzAQX623Rt0xhvh1IoklEAAIBy6GSmXStSjqhTg+qKqBzo7XAKRTIKAABQDv1v60E5XEY3NI/1digXRTIKAABQDn23+YD8bNJ1zXy3i14iGQUAACiXUg5nqEGNUEWFVvJ2KBdFMgoAAFAOncq0K7KK744VzUMyCgAAUM4YY3Qy067wYJJRAAAAeFim3Sm70/j0LPo8JKMAAADlzKlMhyQpnGQUAAAAnnYy0y5JVEYBAADgeSSjAAAA8BqSUQAAAHhNXjLKmFEAAAB4HJVRAAAAeA3JKAAAALzmFMnoWcnJyerUqZMaN26sdu3a6ddffy2w3aZNm9SjRw81bdpUTZs21dy5c0s7NAAAgDJr2tJdGvPv9Vq166iMMfmeK0vJaEBpH2DEiBG67777lJiYqNmzZysxMVG//PJLvjZnzpzRwIEDNWPGDHXp0kVOp1PHjh0r7dAAAADKpGyHU68v2KFMu1Nz1+5Vo+hQDe9ST3e1T5BkddMH+fspOND3O8FLNcJDhw5p9erVGjJkiCTp1ltv1Z49e5SSkpKv3ccff6wOHTqoS5cu+3tMTQAAIABJREFUkiR/f3/VqFGjNEMDAAAos37efUyZdqfu7lhHwzvX08FTWRo7d5N+O3JakpWMhlcOkM1m83Kkl1aqyeiePXtUs2ZNBQRYBVibzaaEhASlpqbma7dlyxZVqlRJ/fv3V+vWrXX33Xfr8OHDpRkaAABAmbVo2yFJ0p+vSdBzNzXT0zc2lSTtPJwhKS8Z9f0ueslHJjA5HA4tXLhQU6dO1bp16xQXF6f777+/wLaTJk1SfHy8+5KRkeHhaAEAALxryfbDqhkRrCYxYZKketVDJUm7z6mMloXxolIpJ6O1a9fW/v375XA4JEnGGKWmpiohISFfu4SEBPXs2VNxcXGy2WwaMmSIVq1aVeA+x4wZo7S0NPclNDS0NF8CAACAT9l95LR2HzmtHk2i3d3w9aqHSJJ2kYzmFx0drTZt2mjmzJmSpDlz5ig+Pl4NGzbM1+6OO+7QL7/8olOnTkmS5s+fr1atWpVmaAAAAGXSku1WF32vK6Ldj1UPDVJYpQDtPnxaWXansh2uMpOMlvps+qlTpyoxMVEvv/yywsPDNX36dElSUlKSBgwYoAEDBighIUFPPfWUOnXqJD8/P8XFxemdd94p7dAAAADKnEXbDinI30+dGkS5H7PZbKpXI0S7j5zWqayys6yT5IFk9P+3d+dxUdX7/8BfA8M2MOwgCAIqm8gmm4ipuZW2mNni7bqmptm3e7/3/upm3Sy1ui339suv1feXdjU0l66Zpl5bvGmuuYCmuIKCrLIvwrDO9vn9MTgyIqgJHGBez8ejx+DMmZn3fBqOLz/bCQkJwdGjR1vdv3r1apM/z5gxAzNmzOjscoiIiIh6rHq1FsevVGLoAFfY25jGuP7u9jhTUI2ia40Aek4Y7RYLmIiIiIjo9o5kVkCt0+P+EM9Wj12fN5pWcA0A4GjLMEpEREREHWjfLeaLXnc9jJ7OM4RR9owSERER0V3T6vR44rMjmLb6GK6U3djCUgiBfemlCHBTGINnSwOat3c6nd/cM8owSkRERER3a8/FEpzMrcIvmRWYsOIQ/ndfJjQ6PS6V1KKwuvGWQ/QAEOCuAHBjeyf2jBIRERGZsezyOsz8IgV7L5bc1fO++CUHVpYyrJweA18XO/xjdwYmffoL/nnoCoBbD9EDgNLWCp5KG+Ofe0oY7fTV9ERERETm5kzBNTybnIqKOjXOFlzD3pfuh6u99W2fd76wGinZlXh8iA8mhHvj/hBPfPpzJlYeyMLFohrYWVkiob9rm8/v726PUlUTAMBJ0TPCKHtGiYiIiDrQoctleObzY6ht0mJ6oh+q6jX423cX7+i5647kAABmJwUAAGytLPHygyH49x/uw/BAN8xKCoCtlWWbzx/gcWMuqaNtz+hz7BlVEhEREfUAO9MK8dLXp2FnZYm1cxIQ5++CvMoGbP21AFNifDA80L3N51bWqbH9dCFi/JwR1c/Z5LFB3o7YOC/xtu9/fWGTpYUMDjY9I+axZ5SIiIioA3xxOBt//OoU3OxtsOX5JMQHuEImk+Fvk8Nha2WB1789i0aNrs3nf5WSB7VWj9nD+//mGvo3r6h3tJUbr1vf3TGMEhEREd0DIQQ++DEdb+26gIEe9tj6QhJCvJTGx/u5KvDnccHIqajHpz9n3vI1NDo91h/NRR9HG0wM9/rNtVzvGe0pi5cAhlEiIiKi30yr0+OVb87gs/1ZiO7njG+eT4KPs12r4+bc1x+DvB2x8kAWMopVrR7ffb4YxTWNmJHoDyvL3x7P/FwVsJAxjBIRERH1eg1qHRasP4ktJwswOsQDm54bCpc2VsxbWVrg/SkR0AmBv357Fnq9MHl87S85sJZb4JkEv3uqyVpugWlD/fFoVN97ep2uxDBKREREdJeu1asxbfUx7E0vxRMxvvh8ZhwU1u0vGIrq54xZwwJwMrcKm1LyjPefLajGidwqTIrqCzcHm3Ze4c68PTkc80YMuOfX6SoMo0RERER3QacXmLb6OH7Nu4YFowbgw6ci73ho/eUHQ+DtZIsPfkhHSU0jACD5SDaAG9s5mRuGUSIiIqK7sPt8Mc4X1mDO8P54beKgu1q17mAjx1uPhUPVpMWyf59HmaoJu9KKkBDginAfp06suvvqGRtQEREREXUDQgisOpAFG7kFXhg98De9xviwPpgw2Avfny1GVZ0Gap0es4cHdGyhPQh7RomIiIju0PHsSqQVVOPJWF+438P8zqWTBkNpI8fRKxXwdrLFA2F9OrDKnoVhlIiIiOgOrTqQBZkMeO4eFwh5OdnilYmhAIBZSQGQ38N2Tj0dh+mJiIiI7kBGsQr7MsowMdwLAe72t3/CbUwf6ocwbyWifJ1vf3AvxjBKREREdAc+P3gFADB/ZMdsmySTyRDr79ohr9WTmW+fMBGRhG7e8JqIurei6gbsOH0VQ/u7Yoifi9Tl9CrsGSUi6mLrj+Xi3e8uwtXeGqFeSoR4KRHq7YhQLyX6u9vf06UAiahzfHE4G1q9wIJRPWcz+Z6CYZSIqAttP3UVb2w/h75OtlDaynHwchn2ppcaH7e2tMBATweEeimNQXWQtyM8lTZ3tZchEXWc6gYNvkrJR3AfB9wf7Cl1Ob0OwygRURfZe7EEL21JQ18nW2xZmAQfZztodHpkl9fhYlENMopVSC9WIaNYhW9PXTV5rrPCqjmgOhp6Ur2UCO6jhL0NT+NEnW3T8TzUNmkxf+RAWFjwH4UdjWcxIqIucPxKBV7Y+Cuc7Kywft5Q+DjbAQCsLC0Q3McQLFuqbtDgUokK6UU1SG8Oqeeu1uDYlUqT4/zdFAjpc2OYP9RLCX83e1jyL0yiDtGk1SH5l2x4OdpiUlRfqcvplRhGiYg62bmr1Zi37gSsLC3w5ZwEDPRwuO1znOysEB/giviAGytthRAoqGpo7kG9EVL3ppfiPxdKjMfZWlkgyNN0mD/ES3lPG3QTmasdpwpRqmrCXx8KhbWc87k7A8MoEVEnyiqrxawvUtCk0+PLOQn3dO1pmUyGfq4K9HNVYFyLq7U0anTILK1tFVLPXq02eb67g02ruaiBng6wtbL8zTUR9WZ6vcCqg1lQ2sjxTIKf1OX0WgyjRESdpPBaA2asPo5rDRqsmh6LxAFunfI+tlaWCPdxahV0K+vUhnBapDIG1ZO5VTicWW48xkIG9He3N5mLGurlCF8XO86NI7P3c3opssrqsGDUAChtraQup9diGCUi6gQVtU2YvuY4CqsbsXxqlElPZldxtbdG0kB3JA10N96n0wvkVdYjo7gGF1uE1O/PFeG7s0XG4+ytLRHcHExDW4RUJwX/QibzsepgFqwsZZgzvL/UpfRqDKNERB1M1ajBrOQUXCmrw9JHw/D4EF+pSzKytJChv7s9+rvbY0K4t/H+erUWl0pqW4XUU3nXTJ7v7WSLkOvD/M29qQM9HDiXjnqdk7lVSM2pwtNxvujjaCt1Ob0awygRUQdq1Ogwb90JnLtagz+PC8bsHtKjorCWI7qfM6L73bhGthACZaqm5jmozXNRi1Q4klmB/RllxuPkFjIM9HBAqLdpSPV2suXeqNQmvV7gl6xyXC6pxagQjzta2NeVPj+YBaDjLv1JbWMYJSLqIBqdHi9u+hXHsyvx7PAA/HFsoNQl3ROZTAZPR1t4OtpiZLCH8X6NTo+c8jpjSM0oVuFikQo7TheaPN/RVo6wvo64L9AdI4M9EN7XifNQCdX1Gmw5mY+Nx/OQXV5nuHMXMMjbEY9EeuORSG/4u9lLWuOVslr850IJxg3yRKCn8vZPoHsiE0L06Ask+/r6oqCgQOoyiMjM6fUCL29Jw7ZTVzElxgcfPhlldsGrplGDS80r+a+H1HNXa9Cg0QEA3OytcV+QO0YGeWBEsDs8lRz6NCfnrlZj/dFc7Ei7ikaNHi4KKzwd3w9x/q7Yc6EEP54vRnWDBgAQ4eOEhyO98XCEN/q5Krq81te2ncVXKXnY8vwwk+3V6LdrL68xjBIR3SMhBJb9+wLWHsnBuEF9sHJ6DOS8vjwAw4bhJ3OrcPBSOQ5cKsPFohrjY4O8HTEy2B2jgjwQG+ACGzm3mOptGjU6fH+2COuP5RrnH0f3c8bMYf54KMLbZFsxjU6Pw5nl2JVWhP9cKIaqUQsAiOrnjEcjvfFQhDf6Nl8sojOVqhpx3wf7EN7XEVsXJnGqSQdhGCUi6kT/s+cS/mfPZSQOcMXaZxO4b2c7SlWNOHSpHAcvl+HQ5XJU1qkBAAprSwwb4IaRwR4YGeyBADcFQ0APll9Zjw3Hc/F1aj6q6jWwtbLAY1E+mJ7ojwjf2++126TV4dClcnx3tgg/XShBbZMhmMb6u+DhCG88HOndaYuK/rE7Hf+7Lwsrp8diQrhXp7yHOWIYJSLqJMm/ZGPZvy8gwscJm54byr0I74JeL3C+sAYHL5fhwKUy/JpbBa3e8FdSP1c7jAwyBNOkgW5s1x5Apxc4eKkM64/lYl9GKYQw7GE7PdEfT8b4/uZtwRo1OuzPKMN3Z4uw92IJ6tU6yGRAvL8rHonyxoRwrw6b8lHXpMWw9/bC3cEGP/2fUbysbgdiGCUi6gTbfi3A//k6DQM97PH1gmFw4+U274mqUYMjWRU4eKkMBy+XIb+yAYBhtX6Mn4thSD/YE4P7OprdfNzurLJOjS0n8rHheC7yKxtgIQPGDeqDGcP8MXyge4f+v2pQ67AvoxS7zhTi5/RSNGr0sJABQ/u74eFIQzC9l8verjmcjbd3XcB7UyJ4xaUOxjBKRNTBfrpQguc3nISXoy22PD+sS+aymRMhBHIq6g3B9FIZjl6pQL2aC6G6CyEETudfw/pjudh1pghqrR7uDtb4XbwfnhnqB58u+H2oa9Jib3opdqUVYv+lMqi1egCAj7MdBnkbLtIwyNsRod5KBLjZ37aXU6PT4/5/7EeTVo/Di0Zzuk0HYxglIupAR7MqMCs5BUobObY8PwwDutn+iL2ROS+EEkKgVNWEvMp6yAA42MrhYCOH0sYKDrbyLh1KblDr8O+0Qqw/louzV6sBAPEBLpie6I+J4d6SXfxA1ajBnoslOHipHBeLapBVVguN7ka8sbWyQEgfpSGcel2/Nb2i2PZTV/GnzafxlwdD8F+je/a2bN0RwygRUQc5W1CNZ/55DDIAX81PbHU9eOoavW0hlBAC5bVq5FTUIbu8Djnldc0/1yO3os7YK3wrCmtLONjI4WArh7L51sFGDgcbKyiv/3w9wBofu368lfGx9oJkdnkdNhzLxZYT+ahp1EJhbYnHhxgWJA3yduyMJrknaq0eWWW1uFhkuFjDxSLDlcXKa5tMjvNxtjOG0x/PF6PwWgOOvjqWl73tBAyjREQdILO0Fk+vOoq6Ji3Wzx2KhP7cf7A76EkLoarq1LhiEjYNt7nl9VA1rxi/TiYD+jrZIcBdgQA3ewS42UMmA2qbtKht1KK2SQtVi5+N9zVqUNukhf4u/3a3llvcFGYN4VXVqMXx7EoAQKCnA2Yk+uPxGB849sBFZYYritUYQmqRChdu6kWde19/vPFImMRV9k4Mo0RE9+jqtQY8+dkRlKma8PnMWIwJ7SN1SdSG2y2EGhXigZFBHp22EKq6QWMaNsvrkF1Rj5zyOuOm7i15OdoiwF2B/u6GwBngbo/+7vbwc1X85nmLQgg0aHSobTQNrCpjcNXcMsyqbhFqhQAeGNwH0xP9MWyAW4/oab4baq0eV8prkVNej1HBHrCz7l3TPLoLhlEiontQXtuEp1ceRXZFHf5najQei/aRuiS6Q521EKq2SWsImcaweb23s944ZaAlD6UN+rvZG3o53e2bf7aHv5sCCuvue2VuIQT0AtziiO4ZwygR0W9U06jBM58fw/nCGrz12GDMHBYgdUl0D263EGpUsAdGBrsjzt8VWr0eOeX1t5zHefPcQ8AQbgOaezf7N4fO6z2dDjbdN3ASdQWGUSKi36BRo8PMNSlIyanES+OD8YexQVKXRB2srYVQ1pYWUOv0rY53srNq7tlUGIfT+7vbw9/NHk52PW8OJVFXaS+v8Z9qRES3oNHp8cLGX5GSU4m59/XHi2O41Utv5Km0xROxvngi1tdkIVRKdiUc7ayMofP60LqLvbXUJRP1OgyjREQ30esFXt6Shp/TS/FkrC9ef2hQr1u0Qa1ZWMgQ4euECF8n/NdoqashMh/S7E5LRNRNCSGw7N/nseN0IR4I64P3p0Tw0pNERJ2IYZSIqIXley5j3dFcJA10w8fPDIHckqdJIqLOxLMsEVGzNYez8fHey4jydcLnM+N4bWoioi7AMEpEBOCbkwV4e9cFBHo6YO2zCdyKh4ioizCMEpHZ232+GIu2noGPsx3Wz03gimkioi7EMEpEZu1IZjn+sOkUXBRW2DBvKLyd7KQuiYjIrDCMEpHZSsu/hue+PAEbKwusm5OA/u72UpdERGR2OCmKiMxSZqkKs5NToBMCa2cnYHBfJ6lLIiIyS+wZJSKzU1BVj+mrU6Bq1OKz6bGID3CVuiQiIrPFnlEiMitlqibMWJOCElUjVvxuCEaHeEpdEhGRWWPPKBGZjeoGDWZ9kYLs8jq8/Vg4JkX1lbokIiKzxzBKRGahQa3DvHWpuFBUg788GILpif5Sl0RERGAYJSIzoNbqsXDjSaTmVOG5Ef3xwv0DpS6JiIiaMYwSUa+m0wu8tCUN+zPK8HScL/760CDIZDKpyyIiomYMo0TUawkhsGTnOfw7rRATBnvh3ccjGESJiLoZhlEi6rX+738uYcOxPAwPdMOKZ6Iht+Qpj4iou+GZmYh6pdWHruDTfZmI7ueMz2fEwUZuKXVJRER0CwyjRNTrfH0iH+98dxHBfRyQPDse9jbcUpmIqLtiGCWiXuXHc8V4desZ+LrYYf3coXCxt5a6JCIiagfDKBH1Gr9kluOPX52Cm4MNNs4bij6OtlKXREREt8EwSkS9wqm8Kjz35QnYWlngyzkJ8Hezl7okIiK6AwyjRNTjXSpR4dm1qdALgeRn4zHI21HqkoiI6A51ehi9fPkykpKSEBwcjPj4eJw/f77NY4UQGDNmDJydnTu7LCLqJfIr6zFjzXHUNWmxakYcYv1dpS6JiIjuQqeH0QULFmD+/Pm4dOkSFi1ahNmzZ7d57PLlyzFwIC/TR0R3plTViOlrjqNU1YTlU6MxKthD6pKIiOgudWoYLS0txYkTJzB9+nQAwBNPPIH8/HxkZma2Ovb8+fPYvn07Xn311c4siYh6ieoGDWauSUFuRT3+NjkCj0T2lbokIiL6DTo1jObn58Pb2xtyuWGPP5lMBj8/P+Tl5Zkcp9Fo8Nxzz2HVqlWwtOTG1ETUvnq1FnPWpiK9WIVFE0Lx+6F+UpdERES/UbdYwLRs2TJMmTIFgwYNuu2xH330EXx9fY3/1dbWdkGFRNRdqLV6LNzwK07mVmHBqAFYeD+n9hAR9WQyIYTorBcvLS1FYGAgKisrIZfLIYSAt7c3Dh8+jMDAQONxI0aMQF5eHmQyGbRaLQoLC+Hn54fU1FR4eLQ/B8zX1xcFBQWd9RGIqBvR6QX++1+nsOtMEX4X3w/vTYmATCaTuiwiIrqN9vJap/aMenp6IiYmBhs2bAAAbN26Fb6+viZBFAAOHTqE3Nxc5OTk4PDhw3B0dEROTs5tgygRmQ8hBN7YcQ67zhTh4Qhv/O1xBlEiot6g04fpV61ahVWrViE4OBjvv/8+kpOTAQDz5s3Dzp07O/vtiaiX+MfuDGw6nocRQe74aGoULC0YRImIeoNOHabvChymJ+r9Vh3Iwns/pGOInzM2zB0Kexu51CUREdFdkGyYnojoXv0rJQ/v/ZCOkD5KJM+OZxAlIuplGEaJqNv6/mwR/vrtWfi5KrB+bgKcFdZSl0RERB2MYZSIuqVDl8vw3/86BXcHG2yYOxSejrZSl0RERJ2AYZSIup1f86qwYP1JKKzlWD93KPzcFFKXREREnYSTr8gsaHR6FFQ1ILeiDrZWlgj1UnLIt5vKKFbh2eRUCAEkPxuPEC+l1CUREVEnYhilXqNRo0NBVT1yyuuRU1GH3Iobt1evNUCnN904wsvRFqHeSoR4KTHIyxEhXkoM9HCAtZwDBlLJq6jHjDXHUa/W4ovZ8Yjxc5G6JCIi6mQMo9SjNKh1yK2sQ055PXIr6pBTYbjNrahHYXUDbt6ozNbKAgFu9hg3yBMBbvbwc1OgvkmHi8U1yChW4UhmBfZnlBmPl1vIEOjpgBAvJUK9HBHqpUSotxJejrbcYL2TldY0Yvqa4yivbcKnv4/BiCBe9IKIyBwwjFK3o2rUILeivkXP5o3QWVLT1Op4Bxs5/N0UiO7nDH83BQLc7A237vbwVNq0GyK1Oj1yKupwsUiFjGIV0otrkF6swo7ThdiBQuNxjrZyhHo3h9PmXtQQLyUcuM1Qh7hWr8aMNSnIq6zH+1Mi8FCEt9QlERFRF+Gm9ySJ6noNcirqWg2n51bUobxW3ep4R1s5+rvbw9/NHgFuCsOtu+HWzd66w3stVY0aXCpR4WKRIaBmFKuQXqSCqklrclw/VzuEejlikJcSIV6OCPVWIsDNnlcHugv1ai2mrT6OU3nX8NrEUCwYNVDqkoiIqIO1l9cYRqlTCCFQWac29mjefHutXtPqOW721i16Nm+EzQA3RbdYbCSEQGF1I9KLDL2n6cUqZBTXIKuszmQ+qo3cAsF9lM1D/c3D/d5KuDvYSFh999Sk1WHeuhM4dLkcC+8fiEUTQqUuiYiIOkF7eY1jjPSbCSFQpmpCzi2G03PL61v1IgJAH0cbBHsqjcPo18Onn5sCjrZWEnyKOyeTyeDjbAcfZzuMHdTHeH+TVoes0jpjD+rFYhXSi2pw9mq1yfPdHayN81BDvJQY5O2IQE8H2FpZdvVH6RZ0eoE/bz6NQ5fL8UyCH155METqkoiISAIMo9QuvV6guKbRdDi9xWr1Bo3O5HiZDOjrZIcIX6dWQ+p+rgoorHvfV85Gbomwvo4I6+tocn9lndpkiD+9RIWTuVU4nFluPMZCBvR3t28VUn2c7WDRi4f6hRB4/duz+P5sMR6O9MY7k8O5QIyIyExxmJ6g1elRVN3YPIezHrnlLXo4K+uh1upNjreQAb4uCtPFQs2B09dFYbY9fXdCrxfIq6w3LpRKb56TmltZb7ITgL21pWGY/6ZFU0523bv3+E69/0M6Vh7IwqhgD/xzZhy30yIi6uU4Z5SMm74bejZNt0TKr6qHRmf6NZBbyODnagicxh5Od3sEuNnDx9mO4aGD1au1uFRSi4ziGpOV/VU3za3t62TbKqQO8LCHlWXP+f/x2f4sfPBjOmL9XbB+bkKv7C0nIiJTDKNm4m43fbeWW8Df9eawaejl9HayhbwHBZze6Pqc3IvNC6UMvagqZJbWQq270VttZSnDQA8HDPJ2NFk01cex/W2tpPBVSh5e23YWoV5KbJ4/DE6K3tHTS0RE7WMY7UXq1VrjFkgtezfb2vTdzsryxnC6u+mwupejba+el9hbaXR65JTXGRdKZTSv7L96rcHkOGeFFUL6KE1CanAfJewl2ht115lC/OGrU/BzVWDL88PgqbSVpA4iIup6DKM9zPVN3429m+U3ejlLVbfe9L3lNkiGW8PPHrfZ9J16j+oGw96o6TeF1NoWuxrIZICfq6J5sdT1/VGV8O/kvVEPXCrDvHWpcFFYY+vCJPRzVXTaexERUffDMNoNXatvsQen8dKWhtBZUdd603dnhdVNYfPGrWsnbPpOvYMQAlevNSC9SIWMEhUuNu+Rml1uujeqrZVhb9SbQ6pbB+yNejK3EtNXp8DGygJfLxiG4D7Ke35NIiLqWbjPqASEEKioU98UNm/cVje03vTd3cEaAe72GBXiYTKc7t9NNn2nnkcmk8HXxbDLwbiwG3ujNmp0yCytNbkEanqxCmcKTPdG9VDaNM9BvbGi/272Rr1YVINnk1MhkwHJs+MZRImIqBWG0XsghECpqslkGL3lbW0bm76HeClNhtMNK9YVUHbzTd+p97C1skS4jxPCfZxM7q+obTIO718Pqak5lTh0+cbeqJYWsua9UU1Dqq+LnUkPfW5FHWasSUGjRo8vZsdjiJ9Ll30+IiLqOThMfxd+PFeEU3nXWlxHve1N3/1vHk7vxZu+U++m0wvkVtQZry6V0RxS827aG1VpI0dI8/B+iJcS/zx0BVerGvD/psVgQri3dB+AiIgkx2H6DrLjdCF+OFcMSwvDZSHjAly46Tv1epYWMgzwcMAADwdMjLgRKuuatLhUojL2pF4sqkFGiQoncquMx/z9iUgGUSIiahd7Ru/ClbLa5jl4dj1qk3GiriKEQElNE9KLa+BkZ8WheSIiAsCe0Q4zwMNB6hKIujWZTAYvJ1t4OXEPUSIiujPs3iMiIiIiyTCMEhEREZFkGEaJiIiISDIMo0REREQkGYZRIiIiIpIMwygRERERSYZhlIiIiIgkwzBKRERERJJhGCUiIiIiyTCMEhEREZFkGEaJiIiISDIMo0REREQkGYZRIiIiIpIMwygRERERSYZhlIiIiIgkwzBKRERERJJhGCUiIiIiyciEEELqIu6FjY0NPDw8uvQ9a2tr4eDg0KXv2VOwbW6N7dI2tk3b2DZtY9vcGtulbWybtnVF25SVlaGpqemWj/X4MCoFX19fFBQUSF1Gt8S2uTW2S9vYNm1j27SNbXNrbJe2sW3aJnXbcJieiIiIiCTDMEpEREREkrFcunTpUqmL6ImGDRsmdQndFtvm1tgubWPbtI1t0za2za2xXdrGtmmblG3DOaNEREREJBkO0xMRERGRZBhGiYiIiEgyDKPtaGxsxOTJkxEcHIyoqCiMHz8emZmZAIDS0lJMmDABQUFBCA8Px8GDByWutms98MADiIyMRHR0NEaMGIFTp04BAC5fvoykpCQEBwcjPj4e58+fl7hS6SQnJ0Mmk2H79u2gqdxHAAAQGElEQVQA+J0BgICAAISEhCA6OhrR0dHYvHkzAH5vAKCpqQkvvvgigoKCEBERgenTpwMw77apqKgwfleio6MRHBwMuVyOyspK/j4B+P777xETE4Po6GiEh4dj3bp1AHiuAYAff/wRcXFxiIyMRGJiItLS0gCYZ9v88Y9/REBAAGQyGU6fPm28v71zS5efdwS1qaGhQXz33XdCr9cLIYT45JNPxKhRo4QQQjz77LNiyZIlQgghUlJShI+Pj1Cr1RJV2vWqqqqMP2/btk1ERkYKIYQYPXq0SE5OFkIIsWXLFhEXFydFeZLLzs4Ww4YNE4mJieLbb78VQvA7I4QQ/v7+4tSpU63u5/dGiD/96U/ixRdfNJ5vioqKhBBsm5b+8Y9/iEceeUQIwd8nvV4vXFxcRFpamhDCcM6xsbERNTU1Zt82lZWVwtXVVZw7d04IIcTBgwfF4MGDhRDm+b05cOCAyM/Pb3X+be/c0tXnHYbRu5Camir8/f2FEELY29sb/7IQQoj4+Hjx008/SVSZtJKTk0VUVJQoKSkRSqVSaDQaIYThZNmnTx9x+fJliSvsWjqdTowdO1acOHFCjBo1yhhG+Z25dRjl90aI2tpaoVQqRXV1tcn9bBtToaGh/H1qptfrhaurqzhw4IAQQoi0tDTRt29f0dTUZPZtk5qaKoKCgkzuUyqV4uTJk2bdNi3Pv+2dW6Q473CY/i6sWLECjz32GCoqKqDRaODl5WV8LCAgAHl5eRJW1/VmzpyJfv364Y033sD69euRn58Pb29vyOVyAIBMJoOfn5/ZtctHH32E4cOHIzY21ngfvzM3zJw5ExEREZg7dy7Kysr4vQGQlZUFV1dXvPvuu4iLi8OIESOwd+9etk0LR44cQVVVFR555BH+PsHwXdi8eTOmTJkCf39/3HfffVi3bh1UKpXZt01QUBAqKipw5MgRAMDOnTuhUqmQnZ1t9m1zXXvnFinOOwyjd+jdd99FZmYm3nvvPalL6Ta+/PJL5Ofn45133sGiRYukLqdbOHfuHLZu3YrFixdLXUq3dPDgQZw5cwa//vor3N3dMWvWLKlL6ha0Wi1yc3MRFhaGEydO4OOPP8bUqVOh1WqlLq3bWLNmDWbOnGn8C9LcabVavPPOO9i2bRtyc3Oxd+9ezJgxg98ZAE5OTvjmm2/w2muvITY2Fv/5z38QFhaG2tpaqUujNvC3+g58+OGH2LZtG/bs2QOFQgGFQgG5XI7i4mLjv7BycnLg5+cncaXSmDVrFp5//nn4+vqiqKgIWq0WcrkcQgjk5eWZVbscOnQIOTk5CAoKAgAUFxdj/vz5WLZsGb8zgPHzWllZ4U9/+hOCg4PRr18/s//e+Pn5wcLCAtOmTQMADBkyBP3790dubq7Ztw0A1NbW4uuvv0ZqaioAwM3Nzex/n06fPo3CwkKMHDkSABAfHw9fX1+cOXPG7NsGAEaPHo3Ro0cDMCwO9PLywvDhw9k2zdo77zo6Onb5eYc9o7fx0Ucf4auvvsJPP/0EZ2dn4/1PPfUUVq5cCQBITU3F1atXMWrUKKnK7FLXrl1DYWGh8c/bt2+Hm5sbPD09ERMTgw0bNgAAtm7dCl9fXwQGBkpVapdbuHAhioqKkJOTg5ycHCQmJuLzzz/HwoULzfo7AwB1dXW4du2a8c9fffUVhgwZwu8NAHd3d4wdOxa7d+8GAGRnZyM7OxvDhw83+7YBgM2bNyMqKgqhoaHG+8z99+l6mLh48SIAIDMzE1lZWQgJCTH7tgGAoqIi489vv/02xowZg8DAQLZNs/bOu5KckzttNmovkJ+fLwCIAQMGiKioKBEVFSUSEhKEEEIUFxeL8ePHi8DAQBEWFiZ+/vlniavtOjk5OSI+Pl6Eh4eLyMhIMXbsWOOk6PT0dJGYmCiCgoJEbGysOHPmjMTVSqvlAiZz/s4IIURWVpaIjo4WERERIjw8XEyaNElkZ2cLIfi9EcLQPvfff7/x9+qbb74RQrBthBBi2LBh4osvvjC5z9x/n4QQYtOmTcbvS3h4uNi4caMQgm0jhBDz5s0TISEhYuDAgWL69OnGHWDMsW3mz58vfHx8hKWlpfD09BQDBw4UQrR/bunq8w4vB0pEREREkuEwPRERERFJhmGUiIiIiCTDMEpEREREkmEYJSIiIiLJMIwSERERkWQYRomIiIhIMgyjRNSrnT59Gv/617+kLsPo2LFjiIiIwJAhQ4yb3HeUnTt34s9//vNtj8vJyTG5iMfNli5disbGxo4sTRIvv/wyli5dKnUZRHQbDKNE1G10xnW1u1sYXbduHX7/+9/j1KlTePDBBzv0tSdNmoTly5ff8+ssW7asU8OoTqfrtNcmop6HYZSIOoRMJsPixYsxZMgQBAcHY+PGjcbHUlNTMWbMGMTFxWHIkCHYsmULgBs9dIsWLUJMTAw+/fRTqNVq/OUvf0F4eDiioqIwYcIE4+t8+OGHSEhIQExMDCZMmIDc3FwAhp68qVOn4tFHH0VYWBjGjBmDyspKlJaW4s0338S+ffsQHR2N559/HgAwbdo0xMXFITIyEg8//DCKi4uN77Fq1SoEBwcjJiYGb7/9NmQy2W0/x81KS0sxZcoUREREIDw8HKtWrQIAvP/++9i8eTM+/fRTREdHm1weFQCSkpJw5MgRAMArr7wCHx8f42MDBgxAXl4eAGD9+vUYOnQoYmJiMHLkSKSlpQEA1q5di8mTJxufs2TJEgQGBiI+Ph6LFy9GQECAyfstWbIEsbGxCAwMxPfffw8AxjYaMWIEoqOjUVpaitWrVyMsLAzR0dGIiIjA8ePHW33mtWvXYsyYMZg0aRLCwsIwcuRI5OTkGB8bPXo0nnjiCURERCAlJQX3338/tm/fbnz+k08+ibVr1wIAZs+ejQULFmDs2LEIDg7GlClToFarAQAajQavvvoqEhISEB0djaeffhpVVVUADJeAfPDBBxEWFoZx48ahoKDglv9/iKib6dTrOxGR2QAgFi9eLIQwXNrSxcVFZGdni6qqKhEdHS0KCwuFEEKUlZWJfv36iYKCApGdnS0AiHXr1hlfZ+nSpWLSpEmisbFRCCFEaWmpEEKIjRs3innz5gmtViuEEOLLL78UDz30kBBCiCVLlgh/f39RXl4uhBBi6tSp4t133xVCCJGcnCwee+wxk1qvv6YQQrz33ntiwYIFQgghzp49K7y8vERRUZEQQog333xTXD9Ntvc5bvb000+LV199VQghRElJifD19RVHjx4VQggxa9YssXz58lu24RtvvCGWLVsmhBAiNjZWJCQkiPPnz4vMzEwRFBQkhBDi8OHDYuLEicb2OXjwoAgLC2v1WXft2iUGDx4sampqhF6vF7Nnzxb+/v5CCGFs9+uXHP3hhx9EcHCwsQ4AxssnCiGEo6Oj8XOr1WqhUqla1Z6cnCysra3FhQsXhBBCfPDBB2L8+PHGx+zs7ER6errx+JaXyhVCiCeeeEIkJycb2yghIUHU1dUJrVYrkpKSxKZNm4QQQvztb38Tb731lvF5b731lnjhhReEEEI8+eSTxu9gQUGBcHd3F0uWLLllWxNR9yGXNAkTUa8yb948AIZevJEjR+LgwYNwd3fHlStXMHHiRJNjMzIyMGDAAFhZWWH69OnG+3ft2oUPPvgANjY2AAAPDw8AwPbt25GamorY2FgArYd6J0yYADc3NwDAsGHDcPbs2Tbr3LRpE9avX4/GxkY0NjbC3d0dAPDzzz9jwoQJ8PLyAgA899xzeOuttwAAR44cafNztOzBBIA9e/bg5MmTAABPT09MmTIFe/bsQWJiYrvtN27cOCxevBgvvPAC5HI5nnrqKezZswc2NjYYO3YsAGDHjh1IS0vD0KFDjc+rrKxEQ0ODyWvt3bsXTz31FJRKJQBg7ty52Ldvn/FxW1tbTJkyxdheWVlZbdY1duxYzJgxA48++igmTpyI4ODgWx6XlJSEQYMGAQDmz5+PxYsXG/8/JSUlISQkpN3P39Ljjz8OhUIBAEhISDDWt337dlRXV2Pr1q0AALVabezx3bt3Lz788EMAgI+PDyZNmnTH70dE0mEYJaJOI5PJIITA4MGDjcPPLeXk5EChUMDC4vYzhoQQeO211zB//vxbPm5ra2v82dLSss35p4cPH8bHH3+Mo0ePwtPTEzt37sSbb77ZZv0t37+tz3E7LV+nPcOGDcO5c+ewY8cOjBkzBuPGjcMbb7wBGxsbTJ061VjHrFmz8O67795TDTY2Nsb7LC0t253HuXXrVpw8eRL79+/HQw89hHfeeQe/+93v7ur9HRwcTP4sl8tN3vPmOapt/f8UQuCTTz7BAw88cNv3vNN2JyJpcc4oEXWY5ORkAIaQeejQIYwYMQJJSUnIzs7Gnj17jMedPn3aOAfwZpMmTcKKFSvQ1NQEACgrKwMATJ48GStXrkRlZSUAw9zBU6dO3bYmR0dHVFdXG/9cVVUFpVIJNzc3qNVq43xOABg9ejR2796N0tJSAMCaNWuMj93N5xg3bhz++c9/Guvftm0bxo8ff9tarayskJiYiLfffhvjxo1DZGQkLly4gP3792PMmDHG9tmwYYNx/qher8eJEydavdaYMWOwdetW1NbWQgiBL7744rbvf51SqTS2mVarRVZWFuLi4vDyyy/jySefREpKyi2fd/ToUaSnpwMAVq9ejdGjR8PS0vKWxwYGBhrnnmZnZ+Pw4cN3VNvkyZOxfPly1NfXAwDq6+tx/vx5AIZ2v/45i4qKsHPnzjv8xEQkJfaMElGH0el0GDJkCOrq6vDxxx8bh0+/++47vPzyy3jppZeg0Wjg5+dnsnilpUWLFuH1119HTEwMrKys0LdvX3z//feYNm0aKioqMHr0aACGkDRnzhwMGTKk3ZrGjh2LDz/8EJGRkUhKSsInn3yCDRs2ICQkBG5ubhg3bhyuXr0KAIiIiMDixYsxfPhwKJVKTJgwAU5OTgAAFxeXO/4cH3/8MRYuXIiIiAgIIfD666+bDKu3Z9y4cdi/fz+GDx8OmUyGhIQEZGRkwNXVFYBhYdHf//53PP7449BqtVCr1Xj44YcRFxdn8jqPPPIIjh8/jujoaDg7O2PUqFHtbufU0ksvvYTx48dDoVBg9+7dmDNnDiorKyGXy+Hh4WH8R8fNkpKSsGjRImRmZsLNzQ1ffvllm+/xyiuvYOrUqYiIiMDgwYPvuH0WLVqEpqYmDB061NjzuWjRIgwePBgrVqzA7NmzERYWBh8fH2OAJ6LuTSaEEFIXQUQ9n0wmQ1VV1R0Hnu5KpVIZ51muWLECP/74I3744QeJq/ptrn8WIQReeuklNDQ04LPPPuuU91q7di22b9/e5j8yiIjawp5RIqIWXn31Vfzyyy/QaDTo27evyTB+TzNz5kzk5OSgsbERgwcPxsqVK6UuiYioFfaMEhEREZFkuICJiIiIiCTDMEpEREREkmEYJSIiIiLJMIwSERERkWQYRomIiIhIMgyjRERERCSZ/w86zr0QlOvSBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 800x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of training and testing loss VS percentage of weights\n",
    "# pruned-\n",
    "fig=plt.figure(figsize=(10, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(list(plot_loss.keys()), list(plot_loss.values()), label = 'training_loss')\n",
    "plt.plot(list(plot_test_loss.keys()), list(plot_test_loss.values()), label = 'testing_loss')\n",
    "\n",
    "plt.title(\"Conv-2 CNN: Loss vs. Percentage of weights pruned\")\n",
    "plt.xlabel(\"percentage of weights pruned\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate 'percentage of weights pruned' vs 'number of epochs' needed until early stopping criterion-\n",
    "plot_number_epochs = {}\n",
    "i = 0\n",
    "\n",
    "for epoch in history_main.keys():\n",
    "    number_epochs = len(history_main[epoch]['accuracy'])\n",
    "    plot_number_epochs[percentage_wts_pruned[i]] = number_epochs\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x560 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of percentage of weights VS number of epochs needed-\n",
    "fig=plt.figure(figsize=(10, 7), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(list(plot_number_epochs.keys()), list(plot_number_epochs.values()))\n",
    "# plt.plot(list(plot_loss.keys()), list(plot_loss.values()), label = 'training_loss')\n",
    "# plt.plot(list(plot_test_loss.keys()), list(plot_test_loss.values()), label = 'testing_loss')\n",
    "\n",
    "plt.title(\"Conv-2 CNN: Percentage of weights pruned VS. number of epochs\")\n",
    "plt.xlabel(\"percentage of weights pruned\")\n",
    "plt.ylabel(\"number of epochs\")\n",
    "# plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
